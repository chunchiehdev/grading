# Gemini API å¢å¼ºæŒ‡å—ï¼šToken è®¡æ•°ä¸æ‰¹å¤„ç† API

**æŠ¥å‘Šæ—¥æœŸ**: 2025-10-29
**ç›®æ ‡**: åœ¨è¯„åˆ†ç³»ç»Ÿä¸­å®æ–½ countTokens å’Œ Batch API åŠŸèƒ½

---

## ğŸ“‹ æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘Šåˆ†æäº† Gemini å®˜æ–¹æ–‡æ¡£ä¸­çš„ä¸¤é¡¹å…³é”®åŠŸèƒ½ï¼š**Token è®¡æ•°** å’Œ **æ‰¹å¤„ç† API**ï¼Œå¹¶æå‡ºäº†åœ¨ç°æœ‰è¯„åˆ†ç³»ç»Ÿä¸­çš„å®ç°æ–¹æ¡ˆã€‚è¿™ä¸¤é¡¹åŠŸèƒ½å¯ä»¥æ˜¾è‘—é™ä½æˆæœ¬å¹¶æå‡ç³»ç»Ÿæ•ˆç‡ã€‚

### æ ¸å¿ƒæ”¶ç›Š
- **Token è®¡æ•°**: ç²¾ç¡®æˆæœ¬é¢„æµ‹ï¼Œé˜²æ­¢é…é¢è¶…é™
- **Batch API**: é™ä½ 50% çš„ API è´¹ç”¨ï¼Œç‰¹åˆ«é€‚åˆæ‰¹é‡è¯„åˆ†åœºæ™¯

---

## ä¸€ã€Token è®¡æ•° (countTokens) è§£æ

### 1.1 ä»€ä¹ˆæ˜¯ Token è®¡æ•°ï¼Ÿ

Token è®¡æ•°æ˜¯åœ¨å‘é€è¯·æ±‚ **ä¹‹å‰** ç²¾ç¡®è®¡ç®—æ‰€éœ€ token æ•°çš„åŠŸèƒ½ã€‚ç›®å‰ä½ ä»¬çš„ç³»ç»Ÿä½¿ç”¨ç²—ç•¥ä¼°ç®—ï¼ˆæ¯ 3.5 ä¸ªå­—ç¬¦ = 1 tokenï¼‰ï¼Œè¿™å¯¼è‡´æˆæœ¬è®¡ç®—ä¸å‡†ç¡®ã€‚

### 1.2 å½“å‰é—®é¢˜

```typescript
// ç°æœ‰çš„ç²—ç•¥ä¼°ç®—æ–¹æ³•ï¼ˆåœ¨ gemini-simple.server.tsï¼‰
const tokenEstimate = Math.ceil(totalPromptLength / 3.5);  // ç²¾åº¦ä½
```

**é—®é¢˜**:
- âŒ æ— æ³•å‡†ç¡®é¢„æµ‹è´¹ç”¨
- âŒ å¯èƒ½è§¦å‘è¶…é…é¢é”™è¯¯
- âŒ æ— æ³•ä¼˜åŒ– token ä½¿ç”¨

### 1.3 Token è®¡æ•°çš„å·¥ä½œåŸç†

Gemini API æä¾›äº† `countTokens` æ–¹æ³•æ¥è·å–ç²¾ç¡®çš„ token æ•°ï¼š

```typescript
// ç²¾ç¡®çš„ Token è®¡æ•°
const response = await ai.models.countTokens({
  model: 'gemini-2.5-flash',
  contents: prompt
});

console.log(`ç²¾ç¡® Token æ•°: ${response.totalTokens}`);
```

### 1.4 åº”ç”¨åœºæ™¯åˆ†æ

#### A. æˆæœ¬é¢„æµ‹
```typescript
interface TokenCostAnalysis {
  totalTokens: number;
  estimatedCost: number;      // åŸºäºå®é™… token æ•°
  costPerToken: number;        // gemini-2.5-flash: $0.075/M input
  maxTokenBudget?: number;     // æ•™å¸ˆè®¾å®šçš„æœ€å¤§ token
}
```

#### B. é…é¢ç®¡ç†
```typescript
// é˜²æ­¢è¶…è¿‡æ—¥é…é¢
async function checkQuotaBeforeGrading(
  submissions: Submission[],
  rubric: Rubric
): Promise<{ canProceed: boolean; totalTokens: number }> {
  let totalTokens = 0;

  for (const submission of submissions) {
    const prompt = buildGradingPrompt(submission, rubric);
    const { totalTokens: count } = await ai.models.countTokens({
      model: 'gemini-2.5-flash',
      contents: prompt
    });
    totalTokens += count;
  }

  const dailyQuota = 250000; // å…è´¹å±‚é™åˆ¶
  return {
    canProceed: totalTokens <= dailyQuota,
    totalTokens
  };
}
```

#### C. åŠ¨æ€è°ƒæ•´
```typescript
// æ ¹æ® token æ•°è°ƒæ•´å‚æ•°
async function optimizeRequest(
  prompt: string,
  maxTokens: number = 8192
): Promise<{ adjusted: boolean; recommendation: string }> {
  const { totalTokens } = await ai.models.countTokens({
    model: 'gemini-2.5-flash',
    contents: prompt
  });

  if (totalTokens > 128000) {  // æ¥è¿‘ä¸Šé™
    return {
      adjusted: true,
      recommendation: 'ä½¿ç”¨æ–‡ä»¶ API ä¸Šä¼ å¤§æ–‡æ¡£ï¼Œè€Œä¸æ˜¯åµŒå…¥æ–‡æœ¬'
    };
  }

  return { adjusted: false, recommendation: 'å‚æ•°å·²ä¼˜åŒ–' };
}
```

---

## äºŒã€æ‰¹å¤„ç† API (Batch API) æ·±åº¦è§£æ

### 2.1 Batch API æ˜¯ä»€ä¹ˆï¼Ÿ

**Batch API** æ˜¯ Gemini çš„å¼‚æ­¥æ‰¹å¤„ç†åŠŸèƒ½ï¼Œç”¨äºåŒæ—¶å¤„ç†å¤šä¸ªè¯·æ±‚ï¼š

| ç‰¹æ€§ | æ ‡å‡† API | Batch API |
|------|---------|----------|
| å“åº”æ—¶é—´ | å®æ—¶ï¼ˆç§’çº§ï¼‰ | å¼‚æ­¥ï¼ˆ24 å°æ—¶å†…ï¼‰ |
| æˆæœ¬ | 100% | **50%**   |
| ä½¿ç”¨åœºæ™¯ | å®æ—¶äº¤äº’ | æ‰¹é‡/éç´§æ€¥ä»»åŠ¡ |
| è¯·æ±‚æ•° | å•ä¸ªæˆ–å°‘é‡ | æˆç™¾ä¸Šåƒ |

### 2.2 ä¸¤ç§æäº¤æ–¹å¼å¯¹æ¯”

#### æ–¹å¼ Aï¼šå†…è”è¯·æ±‚ (Inline Requests)
**é€‚ç”¨**: â‰¤ 20MB çš„å°æ‰¹é‡

```typescript
// ç”¨äºå°æ‰¹é‡ï¼ˆ< 50 ä¸ªè¯·æ±‚ï¼‰
const inlineRequests = [
  {
    contents: [{
      parts: [{
        text: 'è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†è¯„åˆ†: ...'
      }],
      role: 'user'
    }]
  },
  {
    contents: [{
      parts: [{
        text: 'è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†è¯„åˆ†: ...'
      }],
      role: 'user'
    }]
  }
];

const batchJob = await ai.batches.create({
  model: 'gemini-2.5-flash',
  src: inlineRequests,
  config: {
    displayName: 'grading-batch-001'
  }
});

console.log(`åˆ›å»ºæ‰¹å¤„ç†ä»»åŠ¡: ${batchJob.name}`);
```

**ä¼˜ç‚¹**:
- ç®€å•ç›´æ¥
- ä¸éœ€è¦ä¸Šä¼ æ–‡ä»¶
- ç»“æœç›´æ¥è¿”å›

**ç¼ºç‚¹**:
- é™åˆ¶åœ¨ 20MB
- ä¸é€‚åˆå¤§è§„æ¨¡æ‰¹å¤„ç†

---

#### æ–¹å¼ Bï¼šæ–‡ä»¶è¾“å…¥ (Input File - JSONL)
**é€‚ç”¨**: > 50 ä¸ªè¯·æ±‚çš„å¤§æ‰¹é‡

**ç¬¬ä¸€æ­¥ï¼šç”Ÿæˆ JSONL æ–‡ä»¶**
```typescript
import * as fs from 'fs';

interface BatchRequest {
  key: string;
  request: {
    contents: any[];
    config?: any;
  };
}

async function generateBatchJsonl(
  submissions: Submission[],
  rubric: Rubric
): Promise<string> {
  const requests: BatchRequest[] = submissions.map((sub, idx) => ({
    key: `submission-${sub.id}`,
    request: {
      contents: [{
        parts: [{
          text: buildGradingPrompt(sub, rubric)
        }],
        role: 'user'
      }],
      config: {
        responseMimeType: 'application/json',
        temperature: 0.3,
        maxOutputTokens: 8192
      }
    }
  }));

  const jsonlContent = requests
    .map(req => JSON.stringify(req))
    .join('\n');

  const filePath = '/tmp/grading-batch.jsonl';
  fs.writeFileSync(filePath, jsonlContent);

  return filePath;
}
```

**JSONL æ–‡ä»¶æ ¼å¼ç¤ºä¾‹** (`grading-batch.jsonl`):
```jsonl
{"key": "submission-123", "request": {"contents": [{"parts": [{"text": "è¯·è¯„åˆ†æ­¤ä½œä¸š..."}], "role": "user"}], "config": {"responseMimeType": "application/json", "temperature": 0.3}}}
{"key": "submission-124", "request": {"contents": [{"parts": [{"text": "è¯·è¯„åˆ†æ­¤ä½œä¸š..."}], "role": "user"}], "config": {"responseMimeType": "application/json", "temperature": 0.3}}}
{"key": "submission-125", "request": {"contents": [{"parts": [{"text": "è¯·è¯„åˆ†æ­¤ä½œä¸š..."}], "role": "user"}], "config": {"responseMimeType": "application/json", "temperature": 0.3}}}
```

**ç¬¬äºŒæ­¥ï¼šä¸Šä¼ æ–‡ä»¶**
```typescript
async function uploadBatchFile(filePath: string) {
  const uploadedFile = await ai.files.upload({
    file: filePath,
    config: {
      displayName: 'grading-batch-001',
      mimeType: 'jsonl'
    }
  });

  return uploadedFile;
}
```

**ç¬¬ä¸‰æ­¥ï¼šåˆ›å»ºæ‰¹å¤„ç†ä»»åŠ¡**
```typescript
async function createBatchJob(uploadedFile: any) {
  const batchJob = await ai.batches.create({
    model: 'gemini-2.5-flash',
    src: uploadedFile.name,  // ä½¿ç”¨ä¸Šä¼ çš„æ–‡ä»¶
    config: {
      displayName: 'grading-batch-001'
    }
  });

  return batchJob;
}
```

---

### 2.3 æ‰¹å¤„ç†ä»»åŠ¡çš„å®Œæ•´å·¥ä½œæµ

```typescript
interface BatchJobWorkflow {
  step1: 'åˆ›å»ºè¯·æ±‚';
  step2: 'ä¸Šä¼ æ–‡ä»¶ï¼ˆå¦‚éœ€è¦ï¼‰';
  step3: 'æäº¤æ‰¹å¤„ç†ä»»åŠ¡';
  step4: 'è½®è¯¢æ£€æŸ¥çŠ¶æ€';
  step5: 'ä¸‹è½½ç»“æœ';
}
```

#### å®Œæ•´å®ç°ç¤ºä¾‹

```typescript
import { GoogleGenAI } from '@google/genai';
import * as fs from 'fs';

const ai = new GoogleGenAI({
  apiKey: process.env.GEMINI_API_KEY
});

// ============ æ­¥éª¤ 1-3ï¼šåˆ›å»ºå¹¶æäº¤æ‰¹å¤„ç† ============
async function submitGradingBatch(submissions: Submission[], rubric: Rubric) {
  // ç”Ÿæˆ JSONL
  const requests = submissions.map(sub => ({
    key: `submission-${sub.id}`,
    request: {
      contents: [{
        parts: [{
          text: buildGradingPrompt(sub, rubric)
        }],
        role: 'user'
      }],
      config: {
        responseMimeType: 'application/json',
        temperature: 0.3,
        maxOutputTokens: 8192
      }
    }
  }));

  // ä½¿ç”¨å°æ‰¹é‡ï¼ˆ< 20MBï¼‰ï¼Œç›´æ¥ä½¿ç”¨å†…è”æ–¹å¼
  if (submissions.length < 50) {
    const batchJob = await ai.batches.create({
      model: 'gemini-2.5-flash',
      src: requests.map(r => r.request),
      config: {
        displayName: `grading-batch-${Date.now()}`
      }
    });

    return {
      jobId: batchJob.name,
      jobName: batchJob.displayName,
      submittedAt: new Date(),
      totalRequests: submissions.length
    };
  }

  // å¤§æ‰¹é‡ï¼šä¸Šä¼  JSONL æ–‡ä»¶
  const jsonlContent = requests
    .map(r => JSON.stringify(r))
    .join('\n');

  fs.writeFileSync('/tmp/batch.jsonl', jsonlContent);

  const uploadedFile = await ai.files.upload({
    file: '/tmp/batch.jsonl',
    config: { displayName: 'grading-batch', mimeType: 'jsonl' }
  });

  const batchJob = await ai.batches.create({
    model: 'gemini-2.5-flash',
    src: uploadedFile.name,
    config: {
      displayName: `grading-batch-${Date.now()}`
    }
  });

  return {
    jobId: batchJob.name,
    jobName: batchJob.displayName,
    submittedAt: new Date(),
    totalRequests: submissions.length
  };
}

// ============ æ­¥éª¤ 4ï¼šè½®è¯¢æ£€æŸ¥çŠ¶æ€ ============
async function pollBatchStatus(jobId: string) {
  const completedStates = new Set([
    'JOB_STATE_SUCCEEDED',
    'JOB_STATE_FAILED',
    'JOB_STATE_CANCELLED',
    'JOB_STATE_EXPIRED'
  ]);

  let isComplete = false;
  let job: any = null;

  while (!isComplete) {
    job = await ai.batches.get({ name: jobId });

    console.log(`çŠ¶æ€: ${job.state} | æ£€æŸ¥æ—¶é—´: ${new Date().toISOString()}`);

    if (completedStates.has(job.state)) {
      isComplete = true;
    } else {
      // ç­‰å¾… 30 ç§’åé‡æ–°æ£€æŸ¥
      await new Promise(resolve => setTimeout(resolve, 30000));
    }
  }

  return job;
}

// ============ æ­¥éª¤ 5ï¼šä¸‹è½½å¹¶å¤„ç†ç»“æœ ============
async function processBatchResults(job: any) {
  if (job.state !== 'JOB_STATE_SUCCEEDED') {
    console.error(`æ‰¹å¤„ç†å¤±è´¥: ${job.state}`);
    if (job.error) {
      console.error(`é”™è¯¯è¯¦æƒ…: ${job.error}`);
    }
    return [];
  }

  const results: any[] = [];

  // æƒ…å†µ Aï¼šå†…è”ç»“æœ
  if (job.dest?.inlinedResponses) {
    for (const inlineResponse of job.dest.inlinedResponses) {
      if (inlineResponse.response) {
        results.push({
          success: true,
          data: JSON.parse(inlineResponse.response.text)
        });
      } else if (inlineResponse.error) {
        results.push({
          success: false,
          error: inlineResponse.error
        });
      }
    }
  }

  // æƒ…å†µ Bï¼šæ–‡ä»¶ç»“æœï¼ˆJSONLï¼‰
  if (job.dest?.fileName) {
    const fileContent = await ai.files.download({
      file: job.dest.fileName
    });

    const lines = fileContent
      .toString('utf-8')
      .split('\n')
      .filter(line => line.trim());

    for (const line of lines) {
      try {
        const { key, response, error } = JSON.parse(line);

        if (response?.candidates?.[0]?.content?.parts?.[0]?.text) {
          results.push({
            submissionId: key.replace('submission-', ''),
            success: true,
            data: JSON.parse(response.candidates[0].content.parts[0].text)
          });
        } else if (error) {
          results.push({
            submissionId: key.replace('submission-', ''),
            success: false,
            error: error.message
          });
        }
      } catch (e) {
        console.error(`è§£æç»“æœè¡Œå¤±è´¥: ${line}`);
      }
    }
  }

  return results;
}

// ============ ä½¿ç”¨ç¤ºä¾‹ ============
async function gradeSubmissionsInBatch(
  submissions: Submission[],
  rubric: Rubric
) {
  try {
    // æ­¥éª¤ 1-3: æäº¤æ‰¹å¤„ç†
    console.log('ğŸ“¤ æäº¤æ‰¹å¤„ç†ä»»åŠ¡...');
    const batchInfo = await submitGradingBatch(submissions, rubric);
    console.log(`  ä»»åŠ¡å·²æäº¤: ${batchInfo.jobId}`);

    // æ­¥éª¤ 4: è½®è¯¢çŠ¶æ€
    console.log('â³ ç­‰å¾…æ‰¹å¤„ç†å®Œæˆ...');
    const completedJob = await pollBatchStatus(batchInfo.jobId);

    // æ­¥éª¤ 5: å¤„ç†ç»“æœ
    console.log('ğŸ“¥ ä¸‹è½½å¹¶å¤„ç†ç»“æœ...');
    const results = await processBatchResults(completedJob);

    // ä¿å­˜åˆ°æ•°æ®åº“
    for (const result of results) {
      if (result.success) {
        await saveBatchGradingResult(result.submissionId, result.data);
      } else {
        console.error(`è¯„åˆ†å¤±è´¥ - ${result.submissionId}: ${result.error}`);
      }
    }

    return {
      totalProcessed: results.length,
      successful: results.filter(r => r.success).length,
      failed: results.filter(r => !r.success).length
    };
  } catch (error) {
    console.error('æ‰¹å¤„ç†å‡ºé”™:', error);
    throw error;
  }
}
```

---

### 2.4 Batch API çš„ä»»åŠ¡çŠ¶æ€ç®¡ç†

```typescript
enum BatchJobState {
  JOB_STATE_PENDING = 'JOB_STATE_PENDING',      // å¾…å¤„ç†
  JOB_STATE_RUNNING = 'JOB_STATE_RUNNING',      // è¿è¡Œä¸­
  JOB_STATE_SUCCEEDED = 'JOB_STATE_SUCCEEDED',  //   æˆåŠŸ
  JOB_STATE_FAILED = 'JOB_STATE_FAILED',        // âŒ å¤±è´¥
  JOB_STATE_CANCELLED = 'JOB_STATE_CANCELLED',  // å·²å–æ¶ˆ
  JOB_STATE_EXPIRED = 'JOB_STATE_EXPIRED'       // å·²è¿‡æœŸï¼ˆ> 48 å°æ—¶ï¼‰
}
```

**çŠ¶æ€è½¬æ¢å›¾**:
```
PENDING â†’ RUNNING â†’ SUCCEEDED  
                  â†’ FAILED âŒ
                  â†’ CANCELLED âŒ
                  â†’ EXPIRED âŒ
```

---

## ä¸‰ã€åœ¨è¯„åˆ†ç³»ç»Ÿä¸­çš„é›†æˆç­–ç•¥

### 3.1 æ¶æ„æ•´åˆ

```typescript
// app/services/gemini-batch-grading.server.ts (æ–°å¢)

interface BatchGradingRequest {
  submissions: Submission[];
  rubric: Rubric;
  classId: string;
  assignmentId: string;
  priority?: 'immediate' | 'normal' | 'low';
}

interface BatchGradingJob {
  jobId: string;
  status: BatchJobState;
  createdAt: Date;
  estimatedCompletion?: Date;
  totalRequests: number;
  successCount: number;
  failureCount: number;
}

export class BatchGradingService {
  async submitBatch(request: BatchGradingRequest): Promise<BatchGradingJob> {
    // é€‰æ‹©åˆé€‚çš„æäº¤æ–¹å¼
    if (request.submissions.length < 50) {
      return this.submitInlineBatch(request);
    } else {
      return this.submitFileBatch(request);
    }
  }

  private async submitInlineBatch(request: BatchGradingRequest) {
    // å†…è”æ–¹å¼
  }

  private async submitFileBatch(request: BatchGradingRequest) {
    // æ–‡ä»¶æ–¹å¼
  }

  async checkStatus(jobId: string): Promise<BatchGradingJob> {
    // æ£€æŸ¥ä»»åŠ¡çŠ¶æ€
  }

  async retrieveResults(jobId: string): Promise<GradingResult[]> {
    // è·å–å¹¶ä¿å­˜ç»“æœ
  }
}
```

### 3.2 ä¸ BullMQ çš„æ•´åˆ

```typescript
// åœ¨ bullmq-grading.server.ts ä¸­æ·»åŠ æ‰¹å¤„ç†æ”¯æŒ

export const gradingQueue = new Queue('grading', {
  connection: redisConnection,
  defaultJobOptions: {
    attempts: 3,
    backoff: { type: 'exponential', delay: 2000 }
  }
});

// å¿«é€Ÿè¯„åˆ†ï¼ˆå®æ—¶ï¼‰- ä½¿ç”¨æ ‡å‡† API
gradingQueue.add('grade-single', data, { priority: 1 });

// æ‰¹é‡è¯„åˆ†ï¼ˆéå®æ—¶ï¼‰- ä½¿ç”¨ Batch API
gradingQueue.add('grade-batch', data, { priority: 10 });

// Worker é€‰æ‹©åˆé€‚çš„å¤„ç†æ–¹å¼
gradingQueue.process('grade-batch', async (job) => {
  const batchService = getBatchGradingService();
  const batchJob = await batchService.submitBatch(job.data);

  // ä¿å­˜ jobId ç”¨äºåç»­æ£€æŸ¥
  job.data.batchJobId = batchJob.jobId;

  // å¼‚æ­¥æ£€æŸ¥å¹¶æ›´æ–°ç»“æœ
  scheduleBatchStatusCheck(batchJob.jobId);
});
```

### 3.3 UI å®ç°ï¼ˆReact ç»„ä»¶ï¼‰

```typescript
// app/components/batch-grading-status.tsx

export function BatchGradingStatus({ jobId }: { jobId: string }) {
  const [job, setJob] = useState<BatchGradingJob | null>(null);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    const pollStatus = async () => {
      try {
        const response = await fetch(`/api/batch-status/${jobId}`);
        const data = await response.json();
        setJob(data);

        if (!['JOB_STATE_SUCCEEDED', 'JOB_STATE_FAILED'].includes(data.status)) {
          // ç»§ç»­è½®è¯¢
          setTimeout(pollStatus, 30000);
        } else {
          setLoading(false);
        }
      } catch (error) {
        console.error('è·å–æ‰¹å¤„ç†çŠ¶æ€å¤±è´¥:', error);
      }
    };

    pollStatus();
  }, [jobId]);

  if (loading) {
    return (
      <div className="space-y-2">
        <p>æ‰¹å¤„ç†è¿›è¡Œä¸­...</p>
        <p className="text-sm text-gray-500">
          å½“å‰çŠ¶æ€: {job?.status || 'å¾…å¤„ç†'}
        </p>
        <p className="text-sm text-gray-500">
          å·²å®Œæˆ: {job?.successCount || 0} / {job?.totalRequests || 0}
        </p>
      </div>
    );
  }

  return (
    <div>
      {job?.status === 'JOB_STATE_SUCCEEDED' && (
        <div className="text-green-600">
            æ‰¹å¤„ç†å®Œæˆï¼{job.successCount} ä¸ªè¯„åˆ†æˆåŠŸ
        </div>
      )}
      {job?.status === 'JOB_STATE_FAILED' && (
        <div className="text-red-600">
          âŒ æ‰¹å¤„ç†å¤±è´¥ã€‚æˆåŠŸ: {job.successCount}, å¤±è´¥: {job.failureCount}
        </div>
      )}
    </div>
  );
}
```

---

## å››ã€æˆæœ¬ä¸æ€§èƒ½åˆ†æ

### 4.1 æˆæœ¬å¯¹æ¯”ï¼ˆ100 ä¸ªä½œä¸šï¼‰

```
å‡è®¾æ¡ä»¶ï¼š
- 100 ä¸ªå­¦ç”Ÿä½œä¸š
- å¹³å‡æ¯ä¸ª 2000 tokens
- æ€»è®¡ 200,000 tokens
- gemini-2.5-flash: $0.075 / ç™¾ä¸‡ input tokens

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ æ–¹å¼           â”‚ è´¹ç”¨        â”‚ å“åº”æ—¶é—´     â”‚ é€‚ç”¨åœºæ™¯      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ æ ‡å‡† API       â”‚ $0.015      â”‚ å®æ—¶(ç§’çº§)   â”‚ å•ä¸ª/å°‘é‡è¯„åˆ† â”‚
â”‚ Batch API      â”‚ $0.0075    â”‚ å¼‚æ­¥(24h)    â”‚ æ‰¹é‡/éç´§æ€¥   â”‚
â”‚ èŠ‚çœæ¯”ä¾‹       â”‚ 50% èŠ‚çœ    â”‚             â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 é€Ÿåº¦æƒè¡¡

```
Token è®¡æ•°å½±å“ï¼š
- countTokens API è°ƒç”¨: ~100ms per request
- 100 ä¸ªä½œä¸š: +10 ç§’å¼€é”€
- ä½†èƒ½ç²¾ç¡®é¢„æµ‹æˆæœ¬å’Œé˜²æ­¢è¶…é…é¢  

Batch API æƒè¡¡ï¼š
- æäº¤: ç«‹å³å®Œæˆ
- è½®è¯¢: æ¯ 30 ç§’æ£€æŸ¥ä¸€æ¬¡
- æ€»è€—æ—¶: é€šå¸¸ < 1 å°æ—¶ï¼ˆå¤§å¤šæ•°æƒ…å†µï¼‰
- æœ€é•¿: 24 å°æ—¶ï¼ˆSLOï¼‰
```

---

## äº”ã€å®æ–½è·¯çº¿å›¾

### é˜¶æ®µ 1ï¼šToken è®¡æ•°ï¼ˆç¬¬ 1-2 å‘¨ï¼‰
```
[ ] 1. åœ¨ gemini-simple.server.ts æ·»åŠ  countTokens æ–¹æ³•
[ ] 2. åˆ›å»º TokenCostAnalysis æ¥å£
[ ] 3. åœ¨æ‰¹å¤„ç†å‰è¿›è¡Œæˆæœ¬æ£€æŸ¥
[ ] 4. è®°å½• token ä½¿ç”¨ç»Ÿè®¡
```

### é˜¶æ®µ 2ï¼šBatch API é›†æˆï¼ˆç¬¬ 2-4 å‘¨ï¼‰
```
[ ] 1. åˆ›å»º gemini-batch-grading.server.ts
[ ] 2. å®ç°å†…è”æ‰¹å¤„ç†ï¼ˆ< 50 ä¸ªè¯·æ±‚ï¼‰
[ ] 3. å®ç°æ–‡ä»¶æ‰¹å¤„ç†ï¼ˆ> 50 ä¸ªè¯·æ±‚ï¼‰
[ ] 4. é›†æˆçŠ¶æ€è½®è¯¢æœºåˆ¶
[ ] 5. ç»“æœå¤„ç†å’Œæ•°æ®åº“ä¿å­˜
```

### é˜¶æ®µ 3ï¼šUI ä¼˜åŒ–ï¼ˆç¬¬ 4-5 å‘¨ï¼‰
```
[ ] 1. æ·»åŠ æ‰¹å¤„ç†ä»»åŠ¡é˜Ÿåˆ—ç•Œé¢
[ ] 2. å®ç°å®æ—¶çŠ¶æ€æ›´æ–°
[ ] 3. æˆæœ¬é¢„æµ‹æ˜¾ç¤º
[ ] 4. æ‰¹å¤„ç†å†å²è®°å½•
```

---

## å…­ã€å¸¸è§é—®é¢˜ä¸è§£å†³æ–¹æ¡ˆ

### Q1: ä»€ä¹ˆæ—¶å€™é€‰æ‹©å†…è” vs æ–‡ä»¶æ–¹å¼ï¼Ÿ

| æ¡ä»¶ | é€‰æ‹© |
|------|------|
| è¯·æ±‚æ•° < 50 | **å†…è”** (æ›´ç®€å•) |
| è¯·æ±‚æ•° 50-1000 | **æ–‡ä»¶** (æ›´ç¨³å®š) |
| è¯·æ±‚æ•° > 1000 | **åˆ†å¤šä¸ªæ‰¹æ¬¡** + æ–‡ä»¶ |
| æ€»å¤§å° < 20MB | ä¸¤è€…å‡å¯ |
| éœ€è¦ç«‹å³ç»“æœ | **æ ‡å‡† API** |

### Q2: å¦‚ä½•å¤„ç†æ‰¹å¤„ç†å¤±è´¥ï¼Ÿ

```typescript
// é”™è¯¯æ¢å¤ç­–ç•¥
if (job.state === 'JOB_STATE_FAILED') {
  // 1. ä¿å­˜å¤±è´¥çš„ submission IDs
  const failedIds = extractFailedSubmissions(job);

  // 2. ä½¿ç”¨æ ‡å‡† API é‡è¯•ï¼ˆæˆæœ¬ç¨é«˜ä½†ä¿è¯å®Œæˆï¼‰
  for (const id of failedIds) {
    await gradeWithFallback(id);
  }
}
```

### Q3: å¦‚ä½•ç›‘æ§ API é…é¢ï¼Ÿ

```typescript
interface QuotaMonitor {
  dailyLimit: 250000;      // å…è´¹å±‚æ—¥é™
  currentUsage: number;
  remainingTokens: number;
  warningThreshold: 0.8;   // 80% æ—¶è­¦å‘Š
}

async function checkQuotaHealth(): Promise<QuotaMonitor> {
  const usage = await getTokenUsageForDay();
  return {
    dailyLimit: 250000,
    currentUsage: usage,
    remainingTokens: 250000 - usage,
    warningThreshold: 0.8
  };
}
```

---

## ä¸ƒã€å®‰å…¨ä¸æœ€ä½³å®è·µ

### 7.1 é”™è¯¯å¤„ç†

```typescript
try {
  const batchJob = await submitBatch(...);
} catch (error) {
  if (error.code === 'BATCH_SIZE_EXCEEDED') {
    // æ‰¹æ¬¡è¿‡å¤§ï¼Œåˆ†å‰²åé‡è¯•
    await submitInChunks(requests, 50);
  } else if (error.code === 'QUOTA_EXCEEDED') {
    // é…é¢ä¸è¶³ï¼Œå»¶è¿Ÿå¤„ç†
    scheduleRetry(requests, '24h');
  } else if (error.code === 'INVALID_REQUEST') {
    // è¯·æ±‚æ ¼å¼é”™è¯¯ï¼Œè®°å½•æ—¥å¿—
    logInvalidRequest(error, requests);
  }
}
```

### 7.2 ç›‘å¬å’Œå‘Šè­¦

```typescript
// åœ¨ app/services/batch-monitoring.server.ts

export async function monitorBatchJob(jobId: string) {
  const startTime = Date.now();
  const maxDuration = 24 * 60 * 60 * 1000; // 24 å°æ—¶

  while (true) {
    const job = await ai.batches.get({ name: jobId });

    // è®°å½•çŠ¶æ€å˜åŒ–
    if (job.state === 'JOB_STATE_RUNNING') {
      console.log(`[${jobId}] è¿è¡Œä¸­...`);
    }

    // æ£€æŸ¥è¶…æ—¶
    if (Date.now() - startTime > maxDuration) {
      await notifyAdmin(`æ‰¹å¤„ç†ä»»åŠ¡è¶…æ—¶: ${jobId}`);
      break;
    }

    // æ£€æŸ¥å®Œæˆ
    if (['JOB_STATE_SUCCEEDED', 'JOB_STATE_FAILED'].includes(job.state)) {
      await notifyCompletion(jobId, job.state);
      break;
    }

    // ç­‰å¾…åé‡è¯•
    await sleep(30000);
  }
}
```

---

## å…«ã€æ€»ç»“ä¸å»ºè®®

### æ¨èå®æ–½é¡ºåº

1. **ç«‹å³å®æ–½ï¼ˆWeek 1ï¼‰**: Token è®¡æ•° + æˆæœ¬è¿½è¸ª
2. **æ¥ä¸‹æ¥ï¼ˆWeek 2-3ï¼‰**: Batch API å†…è”æ–¹å¼
3. **æœ€åï¼ˆWeek 4+ï¼‰**: æ–‡ä»¶æ–¹å¼ + å®Œæ•´ç›‘æ§

### é¢„æœŸæ”¶ç›Š

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ åŠŸèƒ½         â”‚ æˆæœ¬èŠ‚çœ    â”‚ å®æ–½æ—¶é—´  â”‚ ä¼˜å…ˆçº§          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ countTokens  â”‚ ç²¾ç¡®é¢„ç®—    â”‚ 2 å¤©      â”‚ ğŸ”´ é«˜ (å…ˆåš)    â”‚
â”‚ Batch API    â”‚ 50% è´¹ç”¨    â”‚ 2 å‘¨      â”‚ ğŸŸ¡ ä¸­ (è·Ÿè¿›)    â”‚
â”‚ æ–‡ä»¶ä¸Šä¼  API â”‚ æ›´å¤§æ–‡æ¡£    â”‚ 1 å‘¨      â”‚ ğŸŸ¢ ä½ (å¯é€‰)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ³¨æ„äº‹é¡¹

- âš ï¸ **Batch API ä¸æ˜¯å¹‚ç­‰çš„**: é‡å¤æäº¤ä¼šåˆ›å»ºå¤šä¸ªæ‰¹å¤„ç†ä»»åŠ¡
- âš ï¸ **è¶…è¿‡ 48 å°æ—¶çš„ä»»åŠ¡ä¼šè¿‡æœŸ**: éœ€è¦é‡æ–°æäº¤
- âš ï¸ **ç¼“å­˜å¯ç”¨**: å³ä½¿åœ¨æ‰¹å¤„ç†ä¸­ä¹Ÿèƒ½ä½¿ç”¨ä¸Šä¸‹æ–‡ç¼“å­˜ï¼ˆæˆæœ¬ä¸å˜ï¼‰
-   **ç«‹å³å®æ–½**: Token è®¡æ•°ï¼ˆæ— ç¼ºç‚¹ï¼Œåªæœ‰æ”¶ç›Šï¼‰
-   **çµæ´»é€‰æ‹©**: ä¸ºä¸åŒçš„è¯„åˆ†åœºæ™¯é€‰æ‹©åˆé€‚çš„ API

---

**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æœ€åæ›´æ–°**: 2025-10-29
**ä¸‹ä¸€æ­¥è¡ŒåŠ¨**: è”ç³»å¼€å‘å›¢é˜Ÿï¼Œè§„åˆ’ Token è®¡æ•°çš„å®æ–½
