import { type ActionFunctionArgs } from 'react-router';
import { streamText } from 'ai';
import { createGoogleGenerativeAI } from '@ai-sdk/google';
import { createOpenAI } from '@ai-sdk/openai';
import logger from '@/utils/logger';
import { getKeyHealthTracker } from '@/services/gemini-key-health.server';
import { db } from '@/lib/db.server';
import { getServerLocale } from '@/localization/i18n';

const VLLM_CONFIG = {
  baseURL: process.env.VLLM_BASE_URL || '',
  modelName: process.env.VLLM_MODEL_NAME || '',
  apiKey: process.env.VLLM_API_KEY || '',
  timeoutMs: 1500,
};

function parseEnvInt(name: string, fallback: number, min: number, max: number): number {
  const raw = process.env[name];
  if (!raw) return fallback;

  const parsed = Number.parseInt(raw, 10);
  if (Number.isNaN(parsed)) return fallback;
  if (parsed < min) return min;
  if (parsed > max) return max;
  return parsed;
}

const CHAT_CONTENT_LIMITS = {
  studentMaxChars: parseEnvInt('CHAT_STUDENT_CONTENT_MAX_CHARS', 3000, 500, 30000),
  referenceMaxCharsPerFile: parseEnvInt('CHAT_REFERENCE_CONTENT_MAX_CHARS', 5000, 500, 50000),
  referenceMaxFiles: parseEnvInt('CHAT_REFERENCE_FILES_MAX_COUNT', 5, 1, 30),
  referenceTotalMaxChars: parseEnvInt('CHAT_TOTAL_REFERENCE_MAX_CHARS', 15000, 1000, 100000),
};

function normalizeLanguage(language?: string): 'zh' | 'en' {
  if (!language) return 'zh';
  return language.toLowerCase().startsWith('zh') ? 'zh' : 'en';
}

export async function action({ request }: ActionFunctionArgs) {
  if (request.method !== 'POST') {
    return new Response('Method not allowed', { status: 405 });
  }

  try {
    const { messages: rawMessages, context } = await request.json() as { 
      messages: any[],
      context?: {
        rubricCriterionName?: string;
        rubricCriterionDesc?: string;
        rubricCriterionLevels?: Array<{ score: number; description: string }>;
        sparringQuestion?: {
          ai_hidden_reasoning: string;
          question: string;
          target_quote: string;
        };
        currentKemberLevel?: {
          level: number;
          label: string;
          desc: string;
        } | null;
        language?: string;
        fileId?: string;
        assignmentId?: string;
        gradingSessionId?: string;
      }
    };

    const requestLocale = getServerLocale(request);
    const uiLanguage = normalizeLanguage(context?.language || requestLocale);

    // Convert UIMessage format (parts) to CoreMessage format (content) for streamText
    const messages = rawMessages.map((msg: any) => {
      // If message already has content as string, use it directly
      if (typeof msg.content === 'string') {
        return { role: msg.role, content: msg.content };
      }
      // If message has parts (UIMessage format from DefaultChatTransport), extract text
      if (msg.parts && Array.isArray(msg.parts)) {
        const textContent = msg.parts
          .filter((p: any) => p.type === 'text')
          .map((p: any) => p.text)
          .join('');
        return { role: msg.role, content: textContent };
      }
      // Fallback
      return { role: msg.role, content: String(msg.content || '') };
    });

    let model: ReturnType<ReturnType<typeof createOpenAI>['chat']> | ReturnType<ReturnType<typeof createGoogleGenerativeAI>> | null = null;
    let provider: 'vllm' | 'gemini' = 'vllm';
    let selectedKeyId: string | null = null;
    let selectedModelName = VLLM_CONFIG.modelName;

    const selectGeminiModel = async () => {
      const healthTracker = getKeyHealthTracker();
      const availableKeyIds = ['1'];
      if (process.env.GEMINI_API_KEY2) availableKeyIds.push('2');
      if (process.env.GEMINI_API_KEY3) availableKeyIds.push('3');

      const keyId = await healthTracker.selectBestKey(availableKeyIds);
      if (!keyId) {
        throw new Error('vLLM unavailable and all Gemini API keys are currently throttled or unavailable');
      }

      const keyMap: Record<string, string | undefined> = {
        '1': process.env.GEMINI_API_KEY,
        '2': process.env.GEMINI_API_KEY2,
        '3': process.env.GEMINI_API_KEY3,
      };

      const apiKey = keyMap[keyId];
      if (!apiKey) {
        throw new Error(`Gemini API key ${keyId} is missing`);
      }

      const google = createGoogleGenerativeAI({ apiKey });
      provider = 'gemini';
      selectedKeyId = keyId;
      selectedModelName = 'gemini-2.5-flash';
      model = google('gemini-2.5-flash');
    };

    if (VLLM_CONFIG.baseURL && VLLM_CONFIG.modelName) {
      try {
        const controller = new AbortController();
        const timeoutId = setTimeout(() => controller.abort(), VLLM_CONFIG.timeoutMs);
        const healthResponse = await fetch(`${VLLM_CONFIG.baseURL}/models`, {
          method: 'GET',
          headers: {
            Authorization: `Bearer ${VLLM_CONFIG.apiKey}`,
            'Content-Type': 'application/json',
          },
          signal: controller.signal,
        });
        clearTimeout(timeoutId);

        if (healthResponse.ok) {
          const openai = createOpenAI({
            baseURL: VLLM_CONFIG.baseURL,
            apiKey: VLLM_CONFIG.apiKey,
          });
          model = openai.chat(VLLM_CONFIG.modelName);
          provider = 'vllm';
        } else {
          logger.warn(
            {
              status: healthResponse.status,
            },
            '[Chat API] vLLM health check failed, fallback to Gemini',
          );
          await selectGeminiModel();
        }
      } catch (error) {
        logger.warn(
          {
            error: error instanceof Error ? error.message : String(error),
          },
          '[Chat API] vLLM unavailable, fallback to Gemini',
        );
        await selectGeminiModel();
      }
    } else {
      logger.warn('[Chat API] Missing VLLM_BASE_URL or VLLM_MODEL_NAME, using Gemini fallback');
      await selectGeminiModel();
    }

    if (!model) {
      throw new Error('No available model provider for chat');
    }

    // æå–èƒŒæ™¯èˆ‡ç­‰ç´šè³‡è¨Š
    const rubricCriterionName = context?.rubricCriterionName || 'æ‰¹åˆ¤æ€§åæ€';
    const rubricCriterionDesc = context?.rubricCriterionDesc || '';
    const rubricCriterionLevels = context?.rubricCriterionLevels || [
      { score: 4, description: "æ‰¹åˆ¤æ€§åœ°æª¢è¦–æ—¢æœ‰çŸ¥è­˜ï¼Œè³ªç–‘å‡è¨­ï¼Œä¸¦å› ç¶“é©—è€Œæå‡ºæ–°è§€é»žã€‚" },
      { score: 3, description: "ä¸»å‹•ä¸”è¬¹æ…Žåœ°æ€è€ƒæ—¢æœ‰çŸ¥è­˜ï¼Œä¸¦èƒ½æŠŠç¶“é©—è½‰åŒ–ç‚ºå°çŸ¥è­˜çš„æ–°ç†è§£ã€‚" },
      { score: 2, description: "èƒ½ä½¿ç”¨æ—¢æœ‰çŸ¥è­˜ï¼Œä½†æœªå˜—è©¦åŽ»è©•ä¼°/é‘‘å®šå®ƒï¼›å±•ç¾äº†ç†è§£ï¼Œä½†æ²’æœ‰é€£çµåˆ°å€‹äººå…¶ä»–ç¶“é©—æˆ–åæ‡‰ã€‚" },
      { score: 1, description: "è‡ªå‹•/è¡¨é¢çš„å›žæ‡‰ï¼Œå¹¾ä¹Žæ²’æœ‰æ„è­˜/æ·±æ€ç†Ÿæ…®ï¼Œæˆ–æœªåƒè€ƒæ—¢æœ‰çŸ¥è­˜ï¼›æ²’æœ‰å˜—è©¦åŽ»ç†è§£å°±ç›´æŽ¥å›žæ‡‰ã€‚" }
    ];

    const levelsText = rubricCriterionLevels
      .map((l) => `${uiLanguage === 'zh' ? 'ç­‰ç´š' : 'Level'} ${l.score}: ${l.description}`)
      .join('\n');

    const gradedLevelRef = context?.currentKemberLevel
      ? uiLanguage === 'zh'
        ? `ï¼ˆç³»çµ±åˆæ­¥è©•åˆ†åƒè€ƒï¼š${context.currentKemberLevel.label}ï¼Œä½†è«‹ä½ æ ¹æ“šä»¥ä¸‹ä½œæ¥­å…§å®¹è‡ªè¡Œåˆ¤æ–·ï¼‰`
        : ` (Initial system estimate: ${context.currentKemberLevel.label}. You should still judge independently from the assignment content below.)`
      : '';

    const responseLanguageInstruction = uiLanguage === 'zh'
      ? 'ã€å›žè¦†èªžè¨€ã€‘ä½ å¿…é ˆå…¨ç¨‹ä½¿ç”¨ç¹é«”ä¸­æ–‡å›žè¦†å­¸ç”Ÿã€‚ä¸è¦åˆ‡æ›åˆ°è‹±æ–‡ã€‚'
      : '[Response language] You must reply in English for the entire conversation. Do not switch to Chinese.';

    const kemberLevelHint = uiLanguage === 'zh'
      ? `
ã€ä½ çš„ä»»å‹™ï¼šè©•ä¼°å­¸ç”Ÿçš„ Kember Levelã€‘
è«‹ä½ ä»”ç´°é–±è®€ä¸Šæ–¹ã€Œå­¸ç”Ÿå®Œæ•´ä½œæ¥­å…§å®¹ã€ï¼Œæ ¹æ“šã€Œ${rubricCriterionName} çš„æ¨™æº–ã€ä¸­çš„å››å€‹ç­‰ç´šæè¿°ï¼Œè‡ªè¡Œåˆ¤æ–·å­¸ç”Ÿç›®å‰çš„åæ€æ·±åº¦è½åœ¨å“ªå€‹ç­‰ç´š ${gradedLevelRef}ã€‚

è©•ä¼°æ™‚è«‹æ³¨æ„ï¼š
- å­¸ç”Ÿæœ‰æ²’æœ‰åªæ˜¯ã€ŒåŒæ„ã€èª²æ–‡è§€é»žï¼Œè€Œæ²’æœ‰èªªå‡ºã€Œç‚ºä»€éº¼é€™æ¨£æƒ³ã€ï¼Ÿï¼ˆL1 ç‰¹å¾µï¼‰
- å­¸ç”Ÿæœ‰æ²’æœ‰æåˆ°è‡ªå·±çš„å€‹äººç¶“é©—ï¼Œä½†åªæ˜¯æè¿°ç™¼ç”Ÿäº†ä»€éº¼ï¼Œæ²’æœ‰é€£çµåˆ°çŸ¥è­˜æˆ–ç†è«–ï¼Ÿï¼ˆL2 ç‰¹å¾µï¼‰
- å­¸ç”Ÿæœ‰æ²’æœ‰æŠŠå€‹äººç¶“é©—èˆ‡èª²æœ¬çŸ¥è­˜å»ºç«‹é€£çµï¼Œèªªæ˜Žã€Œé€™å€‹ç¶“é©—è®“æˆ‘å° X æœ‰äº†æ–°çš„ç†è§£ã€ï¼Ÿï¼ˆL3 ç‰¹å¾µï¼‰
- å­¸ç”Ÿæœ‰æ²’æœ‰è³ªç–‘æ—¢æœ‰å‡è¨­ï¼Œæå‡ºç‚ºä»€éº¼èˆŠè§€é»žå¯èƒ½æœ‰å•é¡Œï¼Œä¸¦èªªæ˜Žè‡ªå·±è§€é»žçš„è½‰è®Šï¼Ÿï¼ˆL4 ç‰¹å¾µï¼‰

åœ¨ Stage 2 ä¸­ï¼Œè«‹æ˜Žç¢ºå‘Šè¨´å­¸ç”Ÿä½ è©•ä¼°ä»–ç›®å‰è½åœ¨å“ªå€‹ Levelï¼ˆä¾‹å¦‚ã€Œæˆ‘è¦ºå¾—ä½ ç¾åœ¨å¤§æ¦‚æ˜¯ L2 çš„æ€ç¶­...ã€ï¼‰ï¼Œä»¥åŠè¦å¾€ä¸Šä¸€å€‹ Level éœ€è¦çš„å…·é«”è½‰è®Šã€‚
`
      : `
[Your task: assess the student's Kember Level]
Read the student's full assignment content above and determine the current reflection level using the four level descriptions in "${rubricCriterionName}".${gradedLevelRef}

When assessing, pay attention to:
- Is the student only agreeing with ideas without explaining why? (L1)
- Does the student only describe personal experience without linking to concepts or theory? (L2)
- Does the student connect personal experience with course knowledge to form new understanding? (L3)
- Does the student challenge assumptions and explain a shift in perspective? (L4)

In Stage 2, explicitly tell the student which level they are currently showing (for example, "I think you're currently around L2...") and what concrete change is needed to move up one level.
`;


    const sparContext = context?.sparringQuestion
      ? uiLanguage === 'zh'
        ? `
ã€AI åŽŸæœ¬çš„è§€å¯Ÿã€‘ï¼š${context.sparringQuestion.ai_hidden_reasoning}
ã€é‡å°ä½œæ¥­é€™å¥è©±ã€‘ï¼š${context.sparringQuestion.target_quote}
ã€æœ€åˆæå•ã€‘ï¼š${context.sparringQuestion.question}
`
        : `
[AI initial observation]: ${context.sparringQuestion.ai_hidden_reasoning}
[Target quote from assignment]: ${context.sparringQuestion.target_quote}
[Opening question]: ${context.sparringQuestion.question}
`
      : '';

    logger.info({
      studentMaxChars: CHAT_CONTENT_LIMITS.studentMaxChars,
      referenceMaxCharsPerFile: CHAT_CONTENT_LIMITS.referenceMaxCharsPerFile,
      referenceMaxFiles: CHAT_CONTENT_LIMITS.referenceMaxFiles,
      referenceTotalMaxChars: CHAT_CONTENT_LIMITS.referenceTotalMaxChars,
    }, '[Chat API] Using chat content limits');

    // å–å¾—å­¸ç”Ÿå®Œæ•´ä½œæ¥­å…§å®¹ï¼ˆé€éŽ fileId æŸ¥ UploadedFile.parsedContentï¼‰
    let studentContentSection = '';
    if (context?.fileId) {
      try {
        const uploadedFile = await db.uploadedFile.findUnique({
          where: { id: context.fileId },
          select: { parsedContent: true },
        });
        if (uploadedFile?.parsedContent) {
          const truncated = uploadedFile.parsedContent.length > CHAT_CONTENT_LIMITS.studentMaxChars;
          const content = truncated
            ? uploadedFile.parsedContent.substring(0, CHAT_CONTENT_LIMITS.studentMaxChars) + (uiLanguage === 'zh' ? '\n...ï¼ˆå…§å®¹å·²æˆªå–ï¼‰' : '\n...(content truncated)')
            : uploadedFile.parsedContent;
          studentContentSection = uiLanguage === 'zh'
            ? `\nã€å­¸ç”Ÿå®Œæ•´ä½œæ¥­å…§å®¹ã€‘\n${content}\n`
            : `\n[Student full assignment content]\n${content}\n`;
          logger.info(
            {
              fileId: context.fileId,
              contentLength: uploadedFile.parsedContent.length,
              truncated,
            },
            '[Chat API] Loaded student content',
          );
        }
      } catch (err) {
        logger.warn({ fileId: context.fileId, error: String(err) }, '[Chat API] Failed to load student content');
      }
    }

    // å–å¾—ä½œæ¥­è¦æ±‚èˆ‡åƒè€ƒè³‡æ–™ï¼ˆé€éŽ assignmentId æŸ¥ AssignmentAreaï¼‰
    let assignmentDescSection = '';
    let referenceSection = '';
    if (context?.assignmentId) {
      try {
        const assignment = await db.assignmentArea.findUnique({
          where: { id: context.assignmentId },
          select: {
            name: true,
            description: true,
            referenceFileIds: true,
            customGradingPrompt: true,
          },
        });
        if (assignment) {
          // ä½œæ¥­æè¿°
          if (assignment.description) {
            assignmentDescSection = uiLanguage === 'zh'
              ? `\nã€è€å¸«æŒ‡æ´¾çš„ä½œæ¥­è¦æ±‚ã€‘\nä½œæ¥­åç¨±ï¼š${assignment.name}\n${assignment.description}\n`
              : `\n[Teacher assignment requirements]\nAssignment: ${assignment.name}\n${assignment.description}\n`;
          }
          // è‡ªè¨‚è©•åˆ†æŒ‡ç¤º
          if (assignment.customGradingPrompt) {
            assignmentDescSection += uiLanguage === 'zh'
              ? `\nã€è€å¸«çš„é¡å¤–æŒ‡ç¤ºã€‘\n${assignment.customGradingPrompt}\n`
              : `\n[Teacher additional instructions]\n${assignment.customGradingPrompt}\n`;
          }
          // åƒè€ƒè³‡æ–™
          if (assignment.referenceFileIds) {
            try {
              const refFileIds: string[] = JSON.parse(assignment.referenceFileIds);
              if (refFileIds.length > 0) {
                const refFiles = await db.uploadedFile.findMany({
                  where: { id: { in: refFileIds } },
                  select: { fileName: true, parsedContent: true },
                });
                const limitedRefFiles = refFiles
                  .filter(f => f.parsedContent)
                  .slice(0, CHAT_CONTENT_LIMITS.referenceMaxFiles);

                let totalReferenceChars = 0;
                let truncatedByTotalCount = 0;
                const refContents = limitedRefFiles
                  .map(f => {
                    const raw = f.parsedContent!;
                    const remainingBudget = CHAT_CONTENT_LIMITS.referenceTotalMaxChars - totalReferenceChars;

                    if (remainingBudget <= 0) {
                      truncatedByTotalCount += 1;
                      return null;
                    }

                    const perFileBudget = Math.min(
                      CHAT_CONTENT_LIMITS.referenceMaxCharsPerFile,
                      remainingBudget,
                    );
                    const truncated = raw.length > perFileBudget;
                    const content = truncated
                      ? raw.substring(0, perFileBudget) + (uiLanguage === 'zh' ? '\n...ï¼ˆåƒè€ƒè³‡æ–™å·²æˆªå–ï¼‰' : '\n...(reference truncated)')
                      : raw;

                    totalReferenceChars += content.length;
                    return `[${f.fileName}]\n${content}`;
                  })
                  .filter((v): v is string => Boolean(v));
                if (refContents.length > 0) {
                  referenceSection = uiLanguage === 'zh'
                    ? `\nã€åƒè€ƒè³‡æ–™ã€‘\n${refContents.join('\n\n---\n\n')}\n`
                    : `\n[Reference materials]\n${refContents.join('\n\n---\n\n')}\n`;
                  logger.info(
                    {
                      assignmentId: context.assignmentId,
                      totalReferenceFiles: refFileIds.length,
                      loadedReferenceFiles: limitedRefFiles.length,
                      refCount: refContents.length,
                      truncatedByFileLimit: Math.max(0, refFileIds.length - limitedRefFiles.length),
                      truncatedByTotalLimit: truncatedByTotalCount,
                      totalReferenceChars,
                    },
                    '[Chat API] Loaded reference materials',
                  );
                }
              }
            } catch (parseErr) {
              logger.warn({ error: String(parseErr) }, '[Chat API] Failed to parse referenceFileIds');
            }
          }
        }
      } catch (err) {
        logger.warn(
          { assignmentId: context.assignmentId, error: String(err) },
          '[Chat API] Failed to load assignment context',
        );
      }
    }

    // ============================================================================
    // THE 3-STEP Socratic Guidance System Prompt
    // ============================================================================
    const systemPrompt = `
    ${responseLanguageInstruction}

    ä½ æ˜¯ä¸€ä½æŽ¡ç”¨è˜‡æ ¼æ‹‰åº•ã€ŒèªçŸ¥å¸«å¾’åˆ¶ã€æ–¹æ³•çš„æ•™å­¸åŠ©ç†ã€‚
    ä½ çš„ç›®æ¨™æ˜¯é€éŽã€Œå¤šè¼ªå°è©±ã€ï¼Œå¼•å°Žå­¸ç”Ÿå®Œæˆã€Œ${rubricCriterionName}ã€é€™é …èƒ½åŠ›çš„è‡ªæˆ‘åæ€èˆ‡æˆé•·ã€‚
      
    ã€ä½œæ¥­èƒŒæ™¯èˆ‡æœ€åˆæ„åœ–ã€‘
    ${sparContext}
    ${assignmentDescSection}
    ${studentContentSection}
    ${referenceSection}
      
    ã€è©•åˆ†ç¶­åº¦ï¼š${rubricCriterionName} çš„æ¨™æº–ã€‘
    ${rubricCriterionDesc ? `${rubricCriterionDesc}\n` : ''}${levelsText}
    ${kemberLevelHint}
      
    ã€ä½ çš„å°è©±æŒ‡å°ŽåŽŸå‰‡ï¼šä¸‰æ­¥å¼•å°Žæ³• (3-Stage Guidance)ã€‘
    ç‚ºäº†é¿å…ä¸€æ¬¡çµ¦å‡ºå¤ªå¤šè³‡è¨Šæˆ–ç›´æŽ¥çµ¦ç­”æ¡ˆï¼Œä½ å¿…é ˆæŒ‰ç…§ä»¥ä¸‹éšŽæ®µä¾†å¼•å°Žå°è©±ã€‚
    è«‹æ ¹æ“šä¸Šé¢çš„ \`messages\` æ­·å²ç´€éŒ„ä¾†åˆ¤æ–·æˆ‘å€‘ç¾åœ¨è™•æ–¼å“ªå€‹éšŽæ®µï¼Œä¸¦åŸ·è¡Œå°æ‡‰ç­–ç•¥ï¼š
      
    ---
    ### ðŸ”µ Stage 1: ç¢ºèªç›®æ¨™ (Goal Confirmation)
    **è§¸ç™¼æ™‚æ©Ÿï¼š** é€™æ˜¯ç¬¬ä¸€è¼ªæˆ–æ˜¯å‰å¹¾è¼ªå°è©±ï¼Œå­¸ç”Ÿé‚„ä¸å¤ªæ‡‚ä½ çš„å•é¡Œï¼Œæˆ–è€…å›žç­”é›¢é¡Œã€‚
    **ä½ çš„è¡Œå‹•ï¼š**
    1. æ¾„æ¸…é¡Œæ„ï¼šã€Œå…¶å¯¦æˆ‘æƒ³å•çš„æ˜¯...ã€
    2. åˆ†è§£å•é¡Œï¼šæŠŠå¤§å•é¡Œæ‹†æˆå…·é«”å°å•é¡Œï¼Œä¾‹å¦‚ã€Œä½ æåˆ°çš„ Xï¼Œè·Ÿä½ éŽåŽ»çš„ç¶“é©—æœ‰ä»€éº¼é—œä¿‚ï¼Ÿã€
    3. **åƒè¬ä¸è¦ï¼š** ç›´æŽ¥å‘Šè¨´ä»–æ­£ç¢ºå±¤ç´šæˆ–å®Œç¾Žç­”æ¡ˆã€‚
      
    ---
    ### ðŸŸ¡ Stage 2: è©•ä¼°ç¾ç‹€ (Assess Current State)
    **è§¸ç™¼æ™‚æ©Ÿï¼š** å­¸ç”Ÿå·²ç¶“é‡å°å•é¡Œçµ¦å‡ºäº†å…·é«”çš„æƒ³æ³•æˆ–åæ€å…§å®¹ã€‚
    **ä½ çš„è¡Œå‹•ï¼š**
    1. æ ¹æ“šä¸Šæ–¹çš„ã€Œè©•åˆ†æ¨™æº–ã€ï¼Œåœ¨å…§å¿ƒåˆ¤æ–·ä»–ç¾åœ¨è½åœ¨å“ªä¸€å€‹ã€Œç­‰ç´šã€ã€‚
    2. ç›´æŽ¥æŒ‡å‡ºä»–åšå¾—å¥½çš„åœ°æ–¹ï¼šã€Œæˆ‘çœ‹åˆ°ä½ å·²ç¶“èƒ½æŠŠç¶“é©—å’Œèª²æœ¬ç†è«–é€£çµèµ·ä¾†äº†ï¼ˆå±•ç¾ç­‰ç´š 3 çš„è¡Œç‚ºï¼‰...ã€
    3. æº«å’ŒæŒ‡å‡ºç“¶é ¸ï¼šã€Œä¸éŽåœ¨ã€ŽæŒ‘æˆ°æ—¢æœ‰å‡è¨­ã€é€™éƒ¨åˆ†ï¼Œä½ çš„æè¿°é‚„åœç•™åœ¨...ã€
    4. **åƒè¬ä¸è¦ï¼š** ç›´æŽ¥æ”¹å¯«ä»–çš„å¥å­ã€‚
      
    ---
    ### ðŸŸ¢ Stage 3: ä¸‹ä¸€æ­¥è¡Œå‹•å»ºè­° (Suggest Next Step / Scaffolding)
    **è§¸ç™¼æ™‚æ©Ÿï¼š** å­¸ç”Ÿå·²ç¶“çŸ¥é“è‡ªå·±çš„ä¸è¶³ï¼Œæˆ–è€…ä¸»å‹•è©¢å•ã€Œé‚£æˆ‘è©²æ€Žéº¼æ”¹ã€ã€‚
    **ä½ çš„è¡Œå‹•ï¼š**
    1. çµ¦äºˆã€Œé·¹æž¶ (Scaffolding)ã€ï¼šæä¾›å…·é«”çš„æ€è€ƒæ–¹å‘æˆ–ã€Œä¿®æ”¹å‰ vs é æœŸä¿®æ”¹å¾Œã€çš„æ¯”è¼ƒç¯„ä¾‹ã€‚
    2. é–‹æ”¾æ€§çµå°¾ï¼šã€Œå¦‚æžœæŠŠé‡é»žæ”¾åœ¨ XXXï¼Œä½ è¦ºå¾—é€™å¥å¯ä»¥æ€Žéº¼é‡å¯«æœƒæ›´æ·±å…¥ï¼Ÿã€
    3. é¼“å‹µå­¸ç”Ÿè‡ªå·±å‹•æ‰‹è©¦è©¦çœ‹ã€‚
    ---
      
    ã€èªžè¨€èˆ‡èªžæ°£è¨­å®šã€‘
    1. **å£èªžåŒ–ã€æº«æš–ã€æœ‰åŒç†å¿ƒ**ã€‚ä¸è¦åƒæ©Ÿå™¨äººï¼Œåƒä¸€å€‹ç”¨å¿ƒæŒ‡å°Žçš„å­¸é•·å§ã€‚
    2. æ¯æ¬¡å›žè¦† **æœ€å¤š 3-5 å¥è©±**ã€‚å°è©±è¦ç°¡æ½”ï¼Œç•™ç©ºé–“çµ¦å­¸ç”Ÿè¼¸å…¥ã€‚
    3. çµ•å° **ä¸è¦** è¼¸å‡ºã€Œæˆ‘åˆ¤æ–·ç¾åœ¨æ˜¯ Stage 2ã€é€™ç¨®å…§å¿ƒæ€è€ƒï¼Œç›´æŽ¥å°å­¸ç”Ÿè¬›è©±ã€‚
    `;

    // â”€â”€ Debug: è¼¸å‡ºå®Œæ•´å‚³çµ¦æ¨¡åž‹çš„å…§å®¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    logger.info('[Chat API] ===== FULL PAYLOAD TO MODEL =====');
    logger.info(`[Chat API] UI language: ${uiLanguage}`);
    logger.info('[Chat API] SYSTEM PROMPT:\n' + systemPrompt);
    logger.info('[Chat API] MESSAGES (' + messages.length + ' æ¢):\n' + JSON.stringify(messages, null, 2));
    logger.info(`[Chat API] MODEL: ${selectedModelName} | provider: ${provider} | temperature: 0.7 | maxOutputTokens: 2048`);
    logger.info('[Chat API] ===============================');

    // å•Ÿå‹•ä¸²æµ
    const result = await streamText({
      model,
      system: systemPrompt,
      messages: messages, // History of the conversation!
      temperature: 0.7,
      maxOutputTokens: 2048,
      onFinish: async (completion) => {
        logger.info(
          {
            usage: completion.usage,
            model: selectedModelName,
            provider,
            keyId: selectedKeyId,
          },
          '[Chat API] Stream finished',
        );
        if (provider === 'gemini' && selectedKeyId) {
          const healthTracker = getKeyHealthTracker();
          await healthTracker.recordSuccess(selectedKeyId, 100);
        }
      }
    });

    return result.toTextStreamResponse();
  } catch (error) {
    logger.error({ error: String(error) }, 'Chat endpoint error');
    return new Response(JSON.stringify({ error: String(error) }), { 
      status: 500, 
      headers: { 'Content-Type': 'application/json' }
    });
  }
}
