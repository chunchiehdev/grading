# Implementation Plan: AI Grading with Knowledge Base Context

**Branch**: `004-ai-grading-context` | **Date**: 2025-01-16 | **Spec**: [spec.md](./spec.md)
**Input**: Feature specification from `/specs/004-ai-grading-context/spec.md`

## Summary

Enable teachers to upload reference documents (textbooks, answer keys, lecture notes) and provide custom grading instructions when creating assignments. When students submit work, the system automatically combines these reference materials, custom instructions, rubric criteria, and student work into a comprehensive AI prompt, enabling context-aware grading that judges both correctness and quality.

**Technical Approach**:

- Extend existing database schema (Prisma) with nullable fields for backward compatibility
- Reuse existing file upload/parsing infrastructure (MinIO + PDF parser API)
- Enhance AI grading pipeline (gemini-prompts.server.ts) to compose contextual prompts
- Leverage existing i18n system for language detection
- Maintain graceful degradation when reference materials unavailable

## Technical Context

**Language/Version**: TypeScript 5.x with Node.js 20+ (React Router v7 application)
**Primary Dependencies**:

- Backend: React Router v7, Express, Prisma ORM, Socket.IO
- Frontend: React 19, Radix UI, Tailwind CSS, Framer Motion
- AI: OpenAI API + Google Generative AI (Gemini 2.0 Flash)
- Storage: PostgreSQL (database), MinIO (S3-compatible file storage), Redis (cache/sessions)

**Storage**:

- PostgreSQL with Prisma ORM (custom output: `app/generated/prisma/client`)
- MinIO S3-compatible object storage for files
- Redis for sessions and real-time progress tracking

**Testing**: Vitest + Testing Library + MSW (Mock Service Worker) + jsdom
**Target Platform**: Linux server (Docker containerized), Web browser (modern Chrome/Firefox/Safari)
**Project Type**: Full-stack web application (React Router v7 SSR + API routes)

**Performance Goals**:

- File upload: Handle 5MB PDFs within 3 minutes (including parsing)
- AI grading: Add <2 seconds overhead vs current flow (excluding async parsing)
- Reference document parsing: <60 seconds for 90% of typical materials
- Token management: Prevent prompt overflow with graceful truncation

**Constraints**:

- Backward compatibility: Existing assignments without context must work unchanged
- Token limits: Gemini 1M tokens, OpenAI 128k tokens (target 15k total per grading)
- File formats: PDF, DOCX, TXT only (existing parser limitation)
- Reference content truncation: 8000 chars per document (~2000 tokens)
- Custom instructions: 5000 char limit

**Scale/Scope**:

- Expected: 1-5 reference documents per assignment
- File sizes: Typically 1-10MB per document
- Concurrent users: Existing system scale (teacher + student platforms)
- Data growth: Minimal (reference files stored once, reused across submissions)

## Constitution Check

_GATE: Must pass before Phase 0 research. Re-check after Phase 1 design._

**Constitution Status**: Template constitution not yet configured for this project.

**Default Engineering Principles Applied**:

- ✅ **Backward Compatibility**: All new schema fields nullable, existing workflows unchanged
- ✅ **Graceful Degradation**: System proceeds with grading even if references fail to load
- ✅ **Reuse Existing Infrastructure**: Leveraging current upload, parsing, AI, and i18n systems
- ✅ **Simple Data Model**: JSON array for file IDs, text field for instructions (no new tables)
- ✅ **Testing Strategy**: Contract tests for new API endpoints, integration tests for AI prompt composition
- ✅ **Observability**: Logging for reference loading, token usage, and truncation events

**Architecture Decisions**:

- Direct database relation: `GradingResult.assignmentAreaId` (avoid multi-hop JOINs)
- Stateless prompt composition: Pure function combining context elements
- Fixed truncation strategy: 8000 chars (no dynamic configuration for simplicity)
- Language detection from existing i18n context (no new detection logic)

## Project Structure

### Documentation (this feature)

```
specs/004-ai-grading-context/
├── spec.md              # Feature specification
├── plan.md              # This file (/speckit.plan output)
├── research.md          # Phase 0: Technical decisions and patterns
├── data-model.md        # Phase 1: Schema changes and entity relationships
├── quickstart.md        # Phase 1: Developer setup and usage guide
├── contracts/           # Phase 1: API endpoint contracts
│   ├── upload-reference-files.json    # Teacher uploads reference docs
│   ├── save-custom-instructions.json  # Teacher saves grading instructions
│   └── grade-with-context.json        # Student triggers context-aware grading
└── tasks.md             # Phase 2: Generated by /speckit.tasks (not this command)
```

### Source Code (repository root)

This is a React Router v7 application with integrated frontend/backend:

```
app/
├── routes/                          # File-based routing (React Router v7)
│   ├── teacher/                     # Teacher platform routes
│   │   ├── assignments.create.tsx   # [MODIFIED] Add reference file upload UI
│   │   ├── assignments.$id.edit.tsx # [MODIFIED] Edit reference files/instructions
│   │   └── submissions.$id.tsx      # [MODIFIED] Display used references in review
│   └── student/
│       └── submit.tsx               # [MODIFIED] Pass assignmentAreaId to grading
│
├── api/                             # API endpoints
│   ├── assignments/
│   │   ├── index.ts                 # [MODIFIED] Accept referenceFileIds + customGradingPrompt
│   │   └── $assignmentId.ts         # [MODIFIED] Return reference files + instructions
│   └── grading/
│       └── session.ts               # [MODIFIED] Link GradingResult to AssignmentArea
│
├── services/                        # Business logic layer
│   ├── ai-grader.server.ts          # [MODIFIED] Accept new GradingRequest fields
│   ├── gemini-prompts.server.ts     # [MODIFIED] Add formatReferenceDocuments + formatCustomInstruction
│   ├── openai-simple.server.ts      # [MODIFIED] Mirror Gemini prompt changes
│   ├── grading-engine.server.ts     # [MODIFIED] Load references + compose full context
│   ├── uploaded-file.server.ts      # [REUSED] Existing upload/parse logic
│   └── assignment-area.server.ts    # [NEW] CRUD for reference files + instructions
│
├── components/                      # UI components
│   ├── grading/
│   │   └── ReferenceFileUpload.tsx  # [NEW] Multi-file upload with parse status
│   └── teacher/
│       └── CustomInstructionsField.tsx # [NEW] Text area for grading instructions
│
├── types/                           # TypeScript definitions
│   ├── grading.ts                   # [MODIFIED] Extend GradingRequest interface
│   └── assignment.ts                # [NEW] AssignmentAreaWithReferences type
│
└── schemas/                         # Zod validation schemas
    └── assignment.ts                # [MODIFIED] Add referenceFileIds + customGradingPrompt

prisma/
├── schema.prisma                    # [MODIFIED] Add 3 new fields (see data-model.md)
└── migrations/                      # [NEW] Migration for schema changes

tests/
├── integration/
│   ├── grading-with-context.test.ts # [NEW] End-to-end context-aware grading
│   └── reference-file-upload.test.ts # [NEW] Upload + parse + associate workflow
└── unit/
    ├── gemini-prompts.test.ts       # [MODIFIED] Test new prompt composition
    └── grading-engine.test.ts       # [MODIFIED] Test context loading + truncation
```

**Structure Decision**: React Router v7 collocated architecture - frontend/backend in single `app/` directory. This project uses:

- File-based routing (`app/routes/`) for both UI pages and API endpoints
- Server-side services (`*.server.ts`) for business logic
- Shared components and types across client/server boundaries
- Prisma for database schema and migrations

No new directories needed - all changes integrate into existing structure.

## Complexity Tracking

_No constitution violations - all changes follow existing patterns:_

| Aspect             | Approach                               | Justification                                                           |
| ------------------ | -------------------------------------- | ----------------------------------------------------------------------- |
| Schema Changes     | Add nullable fields to existing tables | Maintains backward compatibility, no data migration needed              |
| Prompt Composition | Pure function with explicit parameters | Testable, debuggable, stateless                                         |
| File Association   | JSON array in single field             | Simple, sufficient for 1-5 files, avoids JOIN complexity                |
| Error Handling     | Graceful degradation at each step      | Follows existing pattern in codebase (see ai-grader.server.ts fallback) |
| Language Detection | Reuse existing i18n context            | Zero new dependencies, leverages proven system                          |

**No Additional Complexity Introduced** - Feature extends existing patterns without new architectural concepts.

## Phase 0: Research & Technical Decisions

**Research Areas** (to be documented in `research.md`):

1. **Token Management Strategy**

   - Current context window limits for Gemini 2.0 Flash (1M) and GPT-4o-mini (128k)
   - Optimal truncation approach: character-based vs sentence-boundary
   - Token estimation accuracy for Chinese + English mixed content

2. **Prompt Engineering Best Practices**

   - Optimal ordering: references → instructions → rubric → student work
   - Separator formatting for AI clarity (markdown sections vs delimiters)
   - Few-shot examples vs zero-shot for context-aware grading

3. **Database Performance**

   - JSON array query performance vs dedicated junction table
   - Index strategy for new fields (assignmentAreaId on GradingResult)
   - Migration strategy for nullable fields (impact on existing queries)

4. **File Upload UX Patterns**

   - Multi-file upload with individual progress indicators
   - Async parse status polling vs WebSocket updates
   - File removal/replacement workflow during assignment edit

5. **I18n Language Detection**
   - react-i18next language resolution mechanism
   - Server-side vs client-side language preference
   - Fallback strategy when language detection fails

**Decisions to Document**:

- Chosen truncation algorithm (simple character limit vs smart truncation)
- Prompt template structure (markdown-based for AI readability)
- JSON array storage justification (vs new ReferenceFileAssociation table)
- Language passing mechanism (via GradingRequest parameter)

## Phase 1: Design Artifacts

**Deliverables**:

1. **`data-model.md`**:

   - Prisma schema additions (3 new fields with types/constraints)
   - Entity relationship diagram updates
   - Migration script outline
   - Backward compatibility verification

2. **`contracts/`**:

   - `POST /api/assignments` - Extended request/response with new fields
   - `PATCH /api/assignments/:id` - Update reference files/instructions
   - `GET /api/assignments/:id` - Include references in response
   - `POST /api/grading/session` - Link to assignmentAreaId
   - Request/response schemas in OpenAPI 3.0 format

3. **`quickstart.md`**:
   - Local development setup (no changes needed - existing Docker Compose)
   - How to test reference file upload locally
   - How to trigger context-aware grading in dev
   - Environment variables (none new required)
   - Sample reference files for testing

**Agent Context Update**:
Run `.specify/scripts/bash/update-agent-context.sh claude` after Phase 1 to:

- Add Prisma schema extension pattern to context
- Document AI prompt composition approach
- Reference graceful degradation pattern

## Next Steps

After `/ speckit.plan` completes:

1. Review generated `research.md` - validate technical decisions
2. Review generated `data-model.md` - verify schema changes
3. Review generated `contracts/` - validate API contracts
4. Run `/speckit.tasks` to generate implementation task breakdown
5. Begin implementation following generated `tasks.md`
