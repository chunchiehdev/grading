/**
 * Agent Executor for Grading
 *
 * Core engine that executes the multi-step Agent grading workflow
 */

import { generateText, stepCountIs } from 'ai';
import { createGoogleGenerativeAI } from '@ai-sdk/google';
import type {
  AgentGradingParams,
  AgentGradingResult,
  AgentStep,
  ParsedCriterion,
  ReferenceDocument,
} from '@/types/agent';
import { agentTools } from './agent-tools.server';
import logger from '@/utils/logger';
import { getKeyHealthTracker } from './gemini-key-health.server';

/**
 * Generate Agent system prompt
 */
function generateAgentSystemPrompt(params: {
  rubricName: string;
  criteria: ParsedCriterion[];
  fileName: string;
  referenceDocuments?: ReferenceDocument[];
  customInstructions?: string;
  assignmentType?: string;
  userLanguage?: string;
}): string {
  const lang = params.userLanguage || 'zh-TW';
  const isZh = lang.startsWith('zh');

  const basePrompt = isZh
    ? `ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„è©•åˆ† Agentï¼Œå°ˆé–€å”åŠ©æ•™å¸«é€²è¡Œä½œæ¥­è©•åˆ†ã€‚`
    : `You are a professional grading Agent specialized in assisting teachers with assignment grading.`;

  const workflow = isZh
    ? `

## è©•åˆ†æµç¨‹

ä½ å¿…é ˆæŒ‰ç…§ä»¥ä¸‹æ­¥é©Ÿé€²è¡Œè©•åˆ†ï¼š

1. **åˆ†æè©•åˆ†æ¨™æº–** - ä½¿ç”¨ \`analyze_rubric\` å·¥å…·ç†è§£è©•åˆ†æ¨™æº–çš„çµæ§‹å’Œè¤‡é›œåº¦
2. **è§£æå­¸ç”Ÿä½œæ¥­** - ä½¿ç”¨ \`parse_content\` å·¥å…·åˆ†æä½œæ¥­å…§å®¹çš„ç‰¹å¾µ
3. **æœå°‹åƒè€ƒè³‡æ–™**ï¼ˆå¦‚æœ‰ï¼‰- ä½¿ç”¨ \`search_reference\` å·¥å…·æŸ¥æ‰¾ç›¸é—œåƒè€ƒæ–‡ä»¶
4. **æª¢æŸ¥ç›¸ä¼¼åº¦** - ä½¿ç”¨ \`check_similarity\` å·¥å…·æª¢æ¸¬æ˜¯å¦æœ‰æŠ„è¥²å«Œç–‘
5. **é€é …è©•åˆ†** - æ ¹æ“šè©•åˆ†æ¨™æº–é€é …çµ¦åˆ†ï¼Œä¸¦æä¾›è©³ç´°è­‰æ“š
6. **è¨ˆç®—ä¿¡å¿ƒåº¦** - ä½¿ç”¨ \`calculate_confidence\` å·¥å…·è©•ä¼°è©•åˆ†çš„å¯é æ€§
7. **ç”Ÿæˆåé¥‹** - ä½¿ç”¨ \`generate_feedback\` å·¥å…·ç”Ÿæˆæœ€çµ‚è©•åˆ†çµæœ

## è©•åˆ†åŸå‰‡

- **è­‰æ“šå°å‘**ï¼šæ¯å€‹åˆ†æ•¸éƒ½è¦æœ‰æ˜ç¢ºçš„è­‰æ“šæ”¯æŒ
- **ä¸€è‡´æ€§**ï¼šç¢ºä¿è©•åˆ†æ¨™æº–çš„ä¸€è‡´æ‡‰ç”¨
- **å»ºè¨­æ€§**ï¼šåé¥‹è¦å…·é«”ä¸”æœ‰åŠ©æ–¼å­¸ç”Ÿæ”¹é€²
- **å…¬æ­£æ€§**ï¼šé¿å…åè¦‹ï¼Œå®¢è§€è©•åƒ¹
- **é€æ˜åº¦**ï¼šæ¸…æ¥šèªªæ˜è©•åˆ†ç†ç”±

## ä¿¡å¿ƒåº¦åˆ¤æ–·

è©•åˆ†å¾Œå¿…é ˆè¨ˆç®—ä¿¡å¿ƒåº¦ï¼Œå¦‚æœä¿¡å¿ƒåº¦ä½æ–¼ 0.7ï¼Œå¿…é ˆæ¨™è¨˜ç‚ºéœ€è¦äººå·¥å¯©æ ¸ã€‚

ä¿¡å¿ƒåº¦å—ä»¥ä¸‹å› ç´ å½±éŸ¿ï¼š
- **Rubric è¦†è“‹ç‡**ï¼šæ˜¯å¦æ‰€æœ‰è©•åˆ†æ¨™æº–éƒ½æœ‰è©•åˆ°
- **è­‰æ“šå“è³ª**ï¼šè©•åˆ†ä¾æ“šæ˜¯å¦å……åˆ†ï¼ˆhigh/medium/lowï¼‰
- **æ¨™æº–æ¨¡ç³Šåº¦**ï¼šè©•åˆ†æ¨™æº–æ˜¯å¦æ¸…æ™°æ˜ç¢ºï¼ˆ0-1ï¼Œè¶Šä½è¶Šå¥½ï¼‰
`
    : `

## Grading Workflow

You must follow these steps:

1. **Analyze Rubric** - Use \`analyze_rubric\` to understand the structure
2. **Parse Content** - Use \`parse_content\` to analyze submission features
3. **Search References** (if available) - Use \`search_reference\` for relevant materials
4. **Check Similarity** - Use \`check_similarity\` to detect potential plagiarism
5. **Grade Each Criterion** - Provide scores with detailed evidence
6. **Calculate Confidence** - Use \`calculate_confidence\` to assess reliability
7. **Generate Feedback** - Use \`generate_feedback\` for final result

## Grading Principles

- **Evidence-based**: Every score must be supported by evidence
- **Consistency**: Apply rubric consistently
- **Constructive**: Provide specific, actionable feedback
- **Fair**: Avoid bias, evaluate objectively
- **Transparent**: Explain grading rationale clearly

## Confidence Threshold

Calculate confidence after grading. If confidence < 0.7, mark for human review.
`;

  return `${basePrompt}

${workflow}

## è©•åˆ†æ¨™æº–ï¼ˆRubricï¼‰

**åç¨±ï¼š** ${params.rubricName}

${params.criteria
  .map(
    (c, idx) => `
### ${idx + 1}. ${c.name}
- **èªªæ˜ï¼š** ${c.description}
- **æ»¿åˆ†ï¼š** ${c.maxScore}
${
  c.levels
    ? `- **è©•åˆ†ç­‰ç´šï¼š**\n${c.levels.map((l) => `  - ${l.score} åˆ†ï¼š${l.description}`).join('\n')}`
    : ''
}
`
  )
  .join('\n')}

${
  params.customInstructions
    ? `
## è€å¸«çš„ç‰¹åˆ¥æŒ‡ç¤º

${params.customInstructions}
`
    : ''
}

${
  params.referenceDocuments && params.referenceDocuments.length > 0
    ? `
## åƒè€ƒè³‡æ–™

è€å¸«æä¾›äº† ${params.referenceDocuments.length} ä»½åƒè€ƒæ–‡ä»¶ï¼Œä½ å¯ä»¥ä½¿ç”¨ \`search_reference\` å·¥å…·æœå°‹ç›¸é—œå…§å®¹ã€‚

åƒè€ƒæ–‡ä»¶ï¼š
${params.referenceDocuments.map((d) => `- ${d.fileName} (${d.contentLength} å­—å…ƒ)`).join('\n')}
`
    : ''
}

## å­¸ç”Ÿä½œæ¥­

**æª”æ¡ˆåç¨±ï¼š** ${params.fileName}
**ä½œæ¥­é¡å‹ï¼š** ${params.assignmentType || 'æœªæŒ‡å®š'}

è«‹é–‹å§‹è©•åˆ†æµç¨‹ã€‚è¨˜ä½ï¼šå¿…é ˆä½¿ç”¨å·¥å…·ä¾†å®Œæˆè©•åˆ†ï¼Œä¸è¦ç›´æ¥çµ¦å‡ºè©•åˆ†çµæœï¼`;
}

/**
 * Execute Agent-based grading
 */
export async function executeGradingAgent(
  params: AgentGradingParams
): Promise<AgentGradingResult> {
  const startTime = Date.now();
  const steps: AgentStep[] = [];

  try {
    logger.info('[Agent Executor] Starting Agent grading', {
      resultId: params.resultId,
      rubricName: params.rubricName,
      criteriaCount: params.criteria.length,
      hasReferences: !!params.referenceDocuments?.length,
    });

    // Get API key from KeyHealthTracker
    const healthTracker = getKeyHealthTracker();
    const availableKeyIds = process.env.GEMINI_API_KEY2 && process.env.GEMINI_API_KEY3
      ? ['1', '2', '3']
      : ['1'];
    const selectedKeyId = await healthTracker.selectBestKey(availableKeyIds);

    if (!selectedKeyId) {
      throw new Error('All Gemini API keys are throttled');
    }

    const apiKey =
      selectedKeyId === '1'
        ? process.env.GEMINI_API_KEY
        : selectedKeyId === '2'
          ? process.env.GEMINI_API_KEY2
          : process.env.GEMINI_API_KEY3;

    if (!apiKey) {
      throw new Error(`API key not found for keyId: ${selectedKeyId}`);
    }

    // Create Gemini provider
    const gemini = createGoogleGenerativeAI({ apiKey });
    const model = gemini('gemini-2.5-flash');

    // Generate system prompt
    const systemPrompt = generateAgentSystemPrompt({
      rubricName: params.rubricName,
      criteria: params.criteria,
      fileName: params.fileName,
      referenceDocuments: params.referenceDocuments,
      customInstructions: params.customInstructions,
      assignmentType: params.assignmentType,
      userLanguage: params.userLanguage,
    });

    // User message (student's work)
    const userMessage = `è«‹è©•åˆ†ä»¥ä¸‹å­¸ç”Ÿä½œæ¥­ï¼š

${params.content}

è¨˜ä½ï¼šä½ å¿…é ˆä½¿ç”¨æä¾›çš„å·¥å…·ä¾†å®Œæˆè©•åˆ†æµç¨‹ã€‚

**é‡è¦ï¼šæœ€å¾Œä¸€æ­¥ä½ å¿…é ˆèª¿ç”¨ generate_feedback å·¥å…·ä¾†ç”Ÿæˆæœ€çµ‚è©•åˆ†çµæœï¼**

è©•åˆ†æµç¨‹ï¼š
1. ä½¿ç”¨ analyze_rubric åˆ†æè©•åˆ†æ¨™æº–
2. ä½¿ç”¨ parse_content è§£æä½œæ¥­å…§å®¹
3. ï¼ˆå¯é¸ï¼‰ä½¿ç”¨ search_reference æœå°‹åƒè€ƒè³‡æ–™
4. ï¼ˆå¯é¸ï¼‰ä½¿ç”¨ check_similarity æª¢æŸ¥ç›¸ä¼¼åº¦
5. é€é …è©•åˆ†ï¼ˆæ€è€ƒæ¯å€‹æ¨™æº–çš„åˆ†æ•¸ï¼‰
6. ä½¿ç”¨ calculate_confidence è¨ˆç®—ä¿¡å¿ƒåº¦
7. **æœ€å¾Œå¿…é ˆä½¿ç”¨ generate_feedback ç”Ÿæˆæœ€çµ‚çµæœ**`;

    // Execute Agent with tools
    const result = await generateText({
      model,
      system: systemPrompt,
      prompt: userMessage,
      tools: agentTools,
      stopWhen: stepCountIs(params.maxSteps || 15),  // Use stopWhen instead of maxSteps
      temperature: 0.3,
      maxTokens: 8192,
      onStepFinish: ({ text, toolCalls, toolResults, usage, finishReason }: any) => {
        // Record each step
        const stepStartTime = Date.now();

        logger.info('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
        logger.info(`ğŸ¤– [Agent Step ${steps.length + 1}] Started`);

        // è¨˜éŒ„ AI çš„æ¨ç†éç¨‹ï¼ˆå¦‚æœæœ‰ï¼‰
        if (text) {
          logger.info('ğŸ’­ [AI Reasoning]:', {
            text: text.substring(0, 200) + (text.length > 200 ? '...' : ''),
            fullLength: text.length,
          });
        }

        if (toolCalls && toolCalls.length > 0) {
          toolCalls.forEach((call: any, idx: number) => {
            const toolResult = toolResults?.[idx];

            logger.info(`ğŸ”§ [Tool Call] ${call.toolName}`, {
              stepNumber: steps.length + 1,
              toolName: call.toolName,
              input: call.args,
            });

            if (toolResult) {
              logger.info(`âœ… [Tool Result] ${call.toolName}`, {
                success: !toolResult.error,
                result: toolResult.result,
                error: toolResult.error,
              });
            }

            const step: AgentStep = {
              stepNumber: steps.length + 1,
              toolName: call.toolName,
              toolInput: call.args,
              toolOutput: toolResult?.result,
              reasoning: text || undefined,
              durationMs: Date.now() - stepStartTime,
              timestamp: new Date(),
            };
            steps.push(step);

            logger.debug('[Agent Step]', {
              stepNumber: step.stepNumber,
              toolName: step.toolName,
              hasOutput: !!step.toolOutput,
            });
          });
        } else if (text) {
          // Pure reasoning step (no tool call)
          logger.info('ğŸ§  [Pure Reasoning Step]', {
            stepNumber: steps.length + 1,
            reasoning: text.substring(0, 300) + (text.length > 300 ? '...' : ''),
          });

          steps.push({
            stepNumber: steps.length + 1,
            reasoning: text,
            durationMs: Date.now() - stepStartTime,
            timestamp: new Date(),
          });
        }

        logger.info('ğŸ“Š [Step Summary]', {
          resultId: params.resultId,
          currentStep: steps.length,
          totalStepsSoFar: steps.length,
          finishReason,
          hasToolCalls: !!toolCalls && toolCalls.length > 0,
          toolNames: toolCalls?.map((c: any) => c.toolName) || [],
          tokensUsed: usage.totalTokens,
          promptTokens: usage.promptTokens,
          completionTokens: usage.completionTokens,
        });
        logger.info('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
      },
    });

    // Record success in KeyHealthTracker
    await healthTracker.recordSuccess(selectedKeyId, Date.now() - startTime);

    // Extract grading result from generate_feedback tool
    logger.info('[Agent Executor] Extracting feedback from steps', {
      resultId: params.resultId,
      totalSteps: result.steps.length,
      toolNames: result.steps.flatMap(s => s.toolCalls?.map((c: any) => c.toolName) || []),
    });

    const feedbackStep = result.steps
      .slice()
      .reverse()
      .find((step) =>
        step.toolCalls?.some((call: any) => call.toolName === 'generate_feedback')
      );

    logger.info('[Agent Executor] Found feedback step', {
      resultId: params.resultId,
      hasFeedbackStep: !!feedbackStep,
      toolResultsCount: feedbackStep?.toolResults?.length || 0,
      toolResults: feedbackStep?.toolResults?.map((r: any) => ({ toolName: r.toolName, hasResult: !!r.result })) || [],
    });

    // Extract feedback result - handle both possible structures
    let feedbackResult: any = null;
    if (feedbackStep?.toolResults) {
      for (const toolResult of feedbackStep.toolResults) {
        // TypeScript workaround: toolResults can have different structures
        const result = (toolResult as any);
        if (result.toolName === 'generate_feedback') {
          feedbackResult = result.result || result;
          break;
        }
      }
    }

    if (!feedbackResult) {
      logger.error('[Agent Executor] No generate_feedback tool call found', {
        resultId: params.resultId,
        totalSteps: result.steps.length,
        stepsWithTools: result.steps.filter(s => s.toolCalls && s.toolCalls.length > 0).length,
        allStepsDetails: result.steps.map(s => ({
          hasToolCalls: !!s.toolCalls,
          toolCallCount: s.toolCalls?.length || 0,
          hasToolResults: !!s.toolResults,
          toolResultCount: s.toolResults?.length || 0,
        })),
      });
      throw new Error('Agent did not generate final feedback using generate_feedback tool');
    }

    // Extract confidence score
    const confidenceStep = result.steps
      .slice()
      .reverse()
      .find((step) =>
        step.toolCalls?.some((call: any) => call.toolName === 'calculate_confidence')
      );

    // Extract confidence result - handle both possible structures
    let confidenceResult: any = null;
    if (confidenceStep?.toolResults) {
      for (const toolResult of confidenceStep.toolResults) {
        const result = (toolResult as any);
        if (result.toolName === 'calculate_confidence') {
          confidenceResult = result.result || result;
          break;
        }
      }
    }

    const confidenceScore: number = confidenceResult?.confidenceScore ?? 0.5;
    const requiresReview = confidenceScore < (params.confidenceThreshold || 0.7);

    // ğŸ” Log the complete feedbackResult structure for debugging
    logger.info('ğŸ” [Agent Executor] feedbackResult structure:', {
      resultId: params.resultId,
      feedbackResult: JSON.stringify(feedbackResult, null, 2),
      hasBreakdown: !!feedbackResult?.breakdown,
      breakdownType: feedbackResult?.breakdown ? typeof feedbackResult.breakdown : 'undefined',
      breakdownIsArray: Array.isArray(feedbackResult?.breakdown),
      breakdownLength: feedbackResult?.breakdown?.length,
    });

    // Convert to standard grading format
    const gradingData = {
      breakdown: feedbackResult.breakdown,
      overallFeedback: feedbackResult.overallFeedback,
      summary: feedbackResult.summary,
    };

    const executionTimeMs = Date.now() - startTime;

    logger.info('[Agent Executor] Agent grading completed', {
      resultId: params.resultId,
      success: true,
      totalSteps: steps.length,
      confidenceScore,
      requiresReview,
      executionTimeMs,
      totalTokens: result.usage.totalTokens,
    });

    return {
      success: true,
      data: gradingData,
      steps,
      confidenceScore,
      requiresReview,
      totalTokens: result.usage.totalTokens ?? 0,
      executionTimeMs,
    };
  } catch (error) {
    const executionTimeMs = Date.now() - startTime;

    logger.error('[Agent Executor] Agent grading failed', {
      resultId: params.resultId,
      error: error instanceof Error ? error.message : String(error),
      steps: steps.length,
      executionTimeMs,
    });

    return {
      success: false,
      steps,
      confidenceScore: 0,
      requiresReview: true,
      totalTokens: 0,
      executionTimeMs,
      error: error instanceof Error ? error.message : 'Unknown error',
    };
  }
}

/**
 * Check if Agent grading is enabled
 */
export function isAgentGradingEnabled(): boolean {
  return process.env.USE_AGENT_GRADING === 'true';
}
