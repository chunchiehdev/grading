/**
 * Agent Executor for Grading (True Agent Pattern)
 *
 * Uses Vercel AI SDK ToolLoopAgent for autonomous grading.
 *
 * Key differences from previous phase-based approach:
 * - All tools available at once (LLM decides order)
 * - Natural thinking flow (no hardcoded phases)
 * - Stops when generate_feedback is called
 * - Transparent reasoning for UI display
 *
 * Inspired by Anthropic's "Building Effective Agents":
 * https://www.anthropic.com/engineering/building-effective-agents
 */

import { ToolLoopAgent, generateObject, type StepResult, type ToolSet } from 'ai';
import { createGoogleGenerativeAI } from '@ai-sdk/google';
import { z } from 'zod';

// ============================================================================
// MODEL PROVIDER CONFIGURATION
// ============================================================================

function createGeminiModel(apiKey: string) {
  const gemini = createGoogleGenerativeAI({ apiKey });
  // Gemini 3 Flash Preview (Correct ID: gemini-3-flash-preview)
  return gemini('gemini-2.5-flash');
}
import type {
  AgentGradingParams,
  AgentGradingResult,
  AgentStep,
  ParsedCriterion,
  ReferenceDocument,
} from '@/types/agent';
import { createAgentTools } from './agent-tools.server';
import logger from '@/utils/logger';
import { getKeyHealthTracker, type ErrorType } from './gemini-key-health.server';

// ============================================================================
// TYPES
// ============================================================================

interface GradingContext {
  rubricName: string;
  criteria: ParsedCriterion[];
  content: string;
  fileName: string;
  referenceDocuments?: ReferenceDocument[];
  assignmentTitle?: string;
  assignmentDescription?: string;
  assignmentType?: string;
  userLanguage?: string;
}

// ============================================================================
// HELPER: Optimize Rubric with LLM
// ============================================================================

async function optimizeRubricWithLLM(
  model: any,
  rubricName: string,
  rawCriteria: ParsedCriterion[]
): Promise<ParsedCriterion[]> {
  logger.info('[Agent] Optimizing rubric...');

  const prompt = `
ä½ æ˜¯ä¸€ä½å°ˆæ¥­çš„æ•™è‚²è©•é‡å°ˆå®¶ã€‚å„ªåŒ–ä»¥ä¸‹è©•åˆ†æ¨™æº–ï¼Œä½¿å…¶å° AI è©•åˆ†åŠ©æ•™æ›´å…·é«”ã€å®¢è§€ä¸”å¯åŸ·è¡Œã€‚

åŸå§‹è©•åˆ†æ¨™æº–åç¨±ï¼š${rubricName}

è¦æ±‚ï¼š
1. ä¿ç•™ï¼šIDã€åç¨±ã€ç¸½åˆ†ä¸è®Š
2. æ“´å……èªªæ˜ï¼šå…·é«”çš„è§€å¯ŸæŒ‡æ¨™ï¼Œå‘Šè¨´ AI æ‡‰è©²å°‹æ‰¾ä»€éº¼è­‰æ“š
3. å„ªåŒ–ç­‰ç´šï¼šæ›´å…·é«”å€åˆ†ä¸åŒåˆ†æ•¸æ®µçš„å·®ç•°

è¼¸å…¥ï¼š${JSON.stringify(rawCriteria, null, 2)}
`;

  try {
    const { object: optimizedCriteria } = await generateObject({
      model,
      schema: z.array(
        z.object({
          criteriaId: z.string(),
          name: z.string(),
          description: z.string(),
          maxScore: z.number(),
          levels: z.array(z.object({ score: z.number(), description: z.string() })).optional(),
        })
      ),
      messages: [{ role: 'user', content: prompt }],
      temperature: 1.0,
      providerOptions: {
        google: {
          safetySettings: [
            { category: 'HARM_CATEGORY_HATE_SPEECH', threshold: 'BLOCK_ONLY_HIGH' },
            { category: 'HARM_CATEGORY_DANGEROUS_CONTENT', threshold: 'BLOCK_ONLY_HIGH' },
            { category: 'HARM_CATEGORY_HARASSMENT', threshold: 'BLOCK_ONLY_HIGH' },
            { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold: 'BLOCK_ONLY_HIGH' },
          ],
        },
      },
    });

    logger.info('[Agent] Rubric optimized', {
      originalCount: rawCriteria.length,
      optimizedCount: optimizedCriteria.length,
    });

    return optimizedCriteria;
  } catch (error) {
    logger.warn('[Agent] Rubric optimization failed, using original', error);
    return rawCriteria;
  }
}

// ============================================================================
// SYSTEM PROMPT (Unified, not phase-locked)
// ============================================================================

function buildGradingSystemPrompt(ctx: GradingContext, isDirectMode: boolean = false): string {
  const lang = ctx.userLanguage || 'zh-TW';
  const isZh = lang.startsWith('zh');

  const baseRole = isZh
    ? `ä½ æ˜¯ä¸€ä½å…·æœ‰ 15 å¹´ç¶“é©—çš„è³‡æ·±å­¸ç§‘æ•™å¸«ï¼Œå°ˆé•·æ–¼å¯«ä½œæ•™å­¸èˆ‡å½¢æˆæ€§è©•é‡ (Formative Assessment)ã€‚
ä½ ç†Ÿæ‚‰ä»¥ä¸‹æ•™è‚²è©•é‡ç†è«–èˆ‡æ–¹æ³•ï¼š
- **Rubric-Based Assessment**ï¼ˆæ¨™æº–æœ¬ä½è©•é‡ï¼‰ï¼šä½¿ç”¨åˆ†æå¼è©•åˆ† (Analytic Scoring)
- **SOLO Taxonomy**ï¼šè©•ä¼°å­¸ç”ŸèªçŸ¥å±¤æ¬¡ï¼ˆPrestructural â†’ Extended Abstractï¼‰
- **Bloom's Taxonomy**ï¼šå€åˆ†è¨˜æ†¶ã€ç†è§£ã€æ‡‰ç”¨ã€åˆ†æã€è©•é‘‘ã€å‰µé€ å±¤æ¬¡
- **Diagnostic Feedback**ï¼ˆè¨ºæ–·æ€§å›é¥‹ï¼‰ï¼šæŒ‡å‡ºå…·é«”å•é¡Œä¸¦æä¾›å¯åŸ·è¡Œçš„æ”¹é€²å»ºè­°

ä½ çš„è©•åˆ†é¢¨æ ¼åš´è¬¹ä½†å…·å»ºè¨­æ€§ï¼Œé‡è¦– Evidence-Based Assessmentï¼ˆè­‰æ“šæœ¬ä½è©•é‡ï¼‰ã€‚`
    : `You are a senior subject teacher with 15 years of experience in writing instruction and formative assessment.
You are proficient in the following educational assessment theories and methods:
- **Rubric-Based Assessment**: Using analytic scoring methodology
- **SOLO Taxonomy**: Evaluating student cognitive levels (Prestructural â†’ Extended Abstract)
- **Bloom's Taxonomy**: Distinguishing between Remember, Understand, Apply, Analyze, Evaluate, Create
- **Diagnostic Feedback**: Identifying specific issues and providing actionable improvement suggestions

Your grading style is rigorous yet constructive, emphasizing evidence-based assessment.`;

  const assignmentInfo = ctx.assignmentTitle
    ? `
## ä½œæ¥­è³‡è¨Š
- æ¨™é¡Œï¼š${ctx.assignmentTitle}
- èªªæ˜ï¼š${ctx.assignmentDescription || 'ç„¡'}
- æª”æ¡ˆï¼š${ctx.fileName}
`
    : `## æª”æ¡ˆï¼š${ctx.fileName}`;

  const rubricInfo = `
## è©•åˆ†æ¨™æº– (Rubric)ï¼š${ctx.rubricName}
${ctx.criteria.map((c, i) => `${i + 1}. **${c.name}** (${c.maxScore}åˆ†): ${c.description}`).join('\n')}

## å°ˆæ¥­è©•é‡ç¶­åº¦åƒè€ƒ (Assessment Dimensions Reference)

åœ¨åˆ†æå­¸ç”Ÿä½œå“æ™‚ï¼Œè«‹è€ƒæ…®ä»¥ä¸‹å°ˆæ¥­è©•é‡ç¶­åº¦ï¼š

### æ–‡ç« çµæ§‹ (Text Structure)
- **Cohesionï¼ˆéŠœæ¥ï¼‰**ï¼šå¥å­ä¹‹é–“çš„é€£æ¥è©ã€æŒ‡ä»£è©ä½¿ç”¨
- **Coherenceï¼ˆé€£è²«ï¼‰**ï¼šæ®µè½ä¹‹é–“çš„é‚è¼¯é—œä¿‚
- **Discourse Markers**ï¼šè½‰æŠ˜è©ã€æ‰¿æ¥è©çš„é©åˆ‡ä½¿ç”¨

### èªè¨€é‹ç”¨ (Language Use)
- **Syntactic Complexityï¼ˆå¥æ³•è¤‡é›œåº¦ï¼‰**ï¼šå¥å‹è®ŠåŒ–ã€å¾å±¬å­å¥ä½¿ç”¨
- **Lexical Diversityï¼ˆè©å½™è±å¯Œåº¦ï¼‰**ï¼šç”¨è©ç²¾æº–åº¦èˆ‡å¤šæ¨£æ€§
- **Mechanicsï¼ˆæ›¸å¯«è¦ç¯„ï¼‰**ï¼šæ¨™é»ç¬¦è™Ÿã€æ ¼å¼è¦ç¯„

### å…§å®¹æ·±åº¦ (Content Depth) - åƒè€ƒ SOLO Taxonomy
- **Prestructuralï¼ˆå‰çµæ§‹ï¼‰**ï¼šé›¢é¡Œæˆ–ç„¡é—œå›æ‡‰
- **Unistructuralï¼ˆå–®é»çµæ§‹ï¼‰**ï¼šåƒ…æä¾›å–®ä¸€æƒ³æ³•
- **Multistructuralï¼ˆå¤šé»çµæ§‹ï¼‰**ï¼šåˆ—èˆ‰å¤šå€‹æƒ³æ³•ä½†ç„¡æ•´åˆ
- **Relationalï¼ˆé—œè¯çµæ§‹ï¼‰**ï¼šæ•´åˆè§€é»ï¼Œæœ‰å› æœé‚è¼¯
- **Extended Abstractï¼ˆå»¶ä¼¸æŠ½è±¡ï¼‰**ï¼šæ‰¹åˆ¤åæ€ï¼Œè¶…è¶Šé¡Œç›®è¦æ±‚

### è­‰æ“šé‹ç”¨ (Evidence & Elaboration)
- **Specificityï¼ˆå…·é«”æ€§ï¼‰**ï¼šæ˜¯å¦æœ‰ sensory detailsã€concrete examples
- **Elaborationï¼ˆé—¡è¿°ï¼‰**ï¼šæ˜¯å¦å……åˆ†è§£é‡‹æƒ³æ³•
- **Evidence-Claim Alignmentï¼ˆè­‰æ“š-è«–é»å°æ‡‰ï¼‰**ï¼šè­‰æ“šæ˜¯å¦æ”¯æŒè«–é»
`;

  const coreInstructions = `
## è©•é‡åŸå‰‡ (Assessment Principles)

### 1. Evidence-Based Scoringï¼ˆè­‰æ“šæœ¬ä½è©•åˆ†ï¼‰
æ‰€æœ‰è©•èªå¿…é ˆå¼•ç”¨ Text Evidenceï¼ˆåŸæ–‡è­‰æ“šï¼‰ï¼Œä½¿ç”¨ã€Œã€æ¨™ç¤ºå¼•ç”¨ã€‚
é¿å… Impressionistic Scoringï¼ˆå°è±¡å¼è©•åˆ†ï¼‰ï¼Œæ¯å€‹åˆ†æ•¸éƒ½éœ€è¦ Justificationï¼ˆçµ¦åˆ†ä¾æ“šï¼‰ã€‚

### 2. Criterion-Referenced Gradingï¼ˆæ¨™æº–åƒç…§è©•åˆ†ï¼‰
åš´æ ¼å°ç…§ Rubric çš„ Performance Levelsï¼ˆè¡¨ç¾ç­‰ç´šï¼‰çµ¦åˆ†ã€‚
é è¨­åˆ†æ•¸ç‚ºæ»¿åˆ†çš„ 80%ï¼ˆProficient Levelï¼‰ï¼Œåªæœ‰é”åˆ° Exemplary æ¨™æº–æ‰çµ¦æ»¿åˆ†ã€‚

### 3. Diagnostic Feedbackï¼ˆè¨ºæ–·æ€§å›é¥‹ï¼‰
çµ¦åˆ†å‰å¿…é ˆé€²è¡Œ Error Analysisï¼ˆéŒ¯èª¤åˆ†æï¼‰ï¼Œæ‰¾å‡ºè‡³å°‘ä¸€å€‹ Area for Improvementã€‚
å›é¥‹éœ€è¦ Actionableï¼ˆå¯åŸ·è¡Œï¼‰ï¼šä¸åªæŒ‡å‡ºå•é¡Œï¼Œé‚„è¦æä¾› Revision Strategyï¼ˆä¿®æ”¹ç­–ç•¥ï¼‰ã€‚

### 4. Authentic Assessment Contextï¼ˆçœŸå¯¦è©•é‡æƒ…å¢ƒï¼‰
é€™æ˜¯ä¸€ä»½**çœŸå¯¦çš„å­¸ç”Ÿä½œæ¥­**ã€‚ç›´æ¥é€²è¡Œ Content Analysisï¼ˆå…§å®¹åˆ†æï¼‰ã€‚
ä¸è¦åœ¨æ€è€ƒæˆ–å›ç­”ä¸­èªªã€Œå‡è¨­ã€ã€ã€Œè™›æ§‹ã€ç­‰å­—çœ¼ã€‚

### 5. Avoid Redundancyï¼ˆé¿å…é‡è¤‡ï¼‰
Feedback è¦ Concise ä¸” Targetedï¼Œä¸è¦é‡è¤‡ç›¸åŒå…§å®¹ã€‚

## è©•åˆ†æ¨ç†è¦æ±‚ï¼ˆæœ€é‡è¦ï¼ï¼‰

ç•¶ä½ èª¿ç”¨ **generate_feedback** æ™‚ï¼Œ**reasoning** æ¬„ä½æ˜¯å¿…å¡«çš„ã€‚

ä½ å¿…é ˆåœ¨ reasoning ä¸­æä¾›å®Œæ•´çš„è©•åˆ†æ¨ç†ï¼Œé€™æœƒé¡¯ç¤ºçµ¦æ•™å¸«å’Œå­¸ç”Ÿçœ‹ï¼š

**reasoning å¿…é ˆåŒ…å«ï¼š**

1. **é€é …åˆ†æ**ï¼šå°æ¯å€‹è©•åˆ†é …ç›®é€²è¡Œåˆ†æ
2. **åŸæ–‡å¼•ç”¨**ï¼šç”¨ã€Œã€æ¨™ç¤ºå¼•ç”¨å­¸ç”Ÿçš„åŸæ–‡
3. **çµ¦åˆ†ç†ç”±**ï¼šè§£é‡‹ç‚ºä»€éº¼çµ¦é€™å€‹åˆ†æ•¸
4. **å„ªç¼ºé»**ï¼šæŒ‡å‡ºåšå¾—å¥½çš„åœ°æ–¹å’Œå¯æ”¹é€²ä¹‹è™•

**ç¯„ä¾‹æ ¼å¼ï¼ˆè«‹æ¨¡ä»¿æ­¤å°ˆæ¥­æ·±åº¦ï¼‰ï¼š**
\`\`\`
ã€è«–é»ç™¼å±• - 3/5 åˆ†ã€‘(SOLO: Multistructural â†’ ç›®æ¨™ Relational)
å­¸ç”Ÿè©¦åœ–è«–è­‰ã€Œç§‘æŠ€ä½¿äººç–é›¢ã€ï¼Œä½† Argumentation å­˜åœ¨ Logical Fallacyï¼ˆé‚è¼¯è¬¬èª¤ï¼‰ã€‚
Text Evidenceï¼šã€Œå¤§å®¶éƒ½åœ¨æ»‘æ‰‹æ©Ÿï¼Œæ‰€ä»¥éƒ½ä¸è¬›è©±äº†ï¼Œé€™å°±æ˜¯ç–é›¢ã€‚ã€
Error Analysisï¼šé€™æ˜¯ Oversimplificationï¼ˆéåº¦ç°¡åŒ–ï¼‰çš„å› æœæ¨è«–ã€‚å­¸ç”Ÿæœªå€åˆ† Physical Presence èˆ‡ Psychological Presence çš„å·®ç•°ã€‚
Revision Strategyï¼šæ‡‰æ·±å…¥æ¢è¨ç§‘æŠ€å¦‚ä½•æ”¹è®Šæºé€šçš„ã€Œè³ªã€ï¼Œå¯å¼•ç”¨ Sherry Turkle çš„ã€ŒAlone Togetherã€æ¦‚å¿µå¢å¼· Persuasivenessã€‚

ã€è­‰æ“šé‹ç”¨ - 2/5 åˆ†ã€‘(Evidence Quality: Weak â†’ ç›®æ¨™ Moderate)
å…¨æ–‡åƒ…ä¾è³´ Anecdotal Evidenceï¼Œç¼ºä¹ Empirical Data æˆ– Expert Sourcesã€‚
Text Evidenceï¼šã€Œæˆ‘æœ‹å‹å°±æ˜¯é€™æ¨£...ã€
Error Analysisï¼šPersonal Anecdote å¯ä½œç‚º Hookï¼Œä½†ä¸èƒ½ä½œç‚ºä¸»è¦ Supporting Evidenceã€‚åœ¨ Academic Writing ä¸­ï¼Œæ­¤é¡è­‰æ“š Credibility è¼ƒä½ã€‚
Revision Strategyï¼šè«‹è£œå…… Statistical Data æˆ– Scholarly Sources ä¾†å¼·åŒ– Evidence-Claim Alignmentã€‚
\`\`\`

## generate_feedback å¿…å¡«æ¬„ä½ï¼ˆé‡è¦ï¼ï¼‰

èª¿ç”¨ generate_feedback æ™‚ï¼Œå¿…é ˆæä¾›ä»¥ä¸‹æ¬„ä½ï¼š

### 1. çµ¦æ•™å¸«çš„å°ˆæ¥­åˆ†æ
- **reasoning**: å®Œæ•´çš„å°ˆæ¥­è©•åˆ†æ¨ç†ï¼Œä½¿ç”¨æ•™è‚²è©•é‡è¡“èªï¼ˆSOLOã€Cohesionã€Evidence ç­‰ï¼‰

### 2. çµ¦å­¸ç”Ÿçš„å‹å–„å›é¥‹ï¼ˆæ–°å¢ï¼ï¼‰
- **messageToStudent**: ç”¨æº«æš–çš„èªæ°£è·Ÿå­¸ç”Ÿèªªè©±ï¼Œåƒç­å°å¸«åœ¨é¼“å‹µå­¸ç”Ÿ
- **topPriority**: é€™æ¬¡æœ€éœ€è¦æ”¹é€²çš„ã€Œä¸€ä»¶äº‹ã€ï¼Œè¦å…·é«”å¯åŸ·è¡Œ
- **encouragement**: å³ä½¿åˆ†æ•¸ä½ï¼Œä¹Ÿè¦æ‰¾å‡ºä¸€å€‹å€¼å¾—è‚¯å®šçš„é»

### 3. å„é …è©•åˆ†
- **criteriaScores**: æ¯å€‹è©•åˆ†é …ç›®çš„è©³ç´°è³‡æ–™
  - criteriaId, name, score, maxScore
  - evidence: é—œéµå¼•ç”¨ï¼ˆæœ€å¤š 50 å­—ï¼‰
  - analysis: ã€çµ¦å­¸ç”Ÿã€‘å£èªåŒ–çš„æ”¹é€²å»ºè­°
  - justification: ã€çµ¦æ•™å¸«ã€‘å°ˆæ¥­è¡“èªçš„çµ¦åˆ†ç†ç”±

### 4. æ•´é«”æ‘˜è¦
- **overallObservation**: æ•´é«”è§€å¯Ÿ
- **strengths**: å„ªé»ï¼ˆ2-3 å€‹ï¼‰
- **improvements**: æ”¹é€²æ–¹å‘ï¼ˆ2-3 å€‹ï¼‰

## èªæ°£å€åˆ†ï¼ˆæœ€é‡è¦ï¼ï¼‰

| æ¬„ä½ | å°è±¡ | èªæ°£ | ç¯„ä¾‹ |
|-----|-----|-----|-----|
| **reasoning** | æ•™å¸« | å°ˆæ¥­è¡“èª | ã€ŒSyntactic Complexity åä½ï¼Œä¸»è¦ç‚º Simple Sentences...ã€ |
| **messageToStudent** | å­¸ç”Ÿ | åƒè€å¸«èªªè©± | ã€Œä½ å¥½ï¼é€™æ¬¡ä½œæ¥­æˆ‘çœ‹åˆ°ä½ æœ‰è‡ªå·±çš„æƒ³æ³•ï¼Œä¸éå¥å­å¯ä»¥å†é †ä¸€é»...ã€ |
| **analysis** | å­¸ç”Ÿ | å£èªåŒ–å»ºè­° | ã€Œé€™å€‹å¥è™Ÿæ”¾éŒ¯ä½ç½®äº†å–”ï¼Œæ‡‰è©²æ”¾åœ¨...ã€ |
| **justification** | æ•™å¸« | å°ˆæ¥­ç°¡æ½” | ã€ŒMechanics Error é »ç¹ï¼Œç¬¦åˆ Level 1 æ¨™æº–ã€ |

âš ï¸ **messageToStudent å’Œ analysis è¦åƒã€Œè€å¸«åœ¨èªªè©±ã€ï¼Œä¸æ˜¯ã€Œå ±å‘Šåœ¨é™³è¿°ã€ï¼**
`;

  const toolGuidance = `
## å¯ç”¨å·¥å…·
1. **think_aloud** - ğŸ§  Hattie & Timperley åˆ†æ (Feed Up, Feed Back, Feed Forward)
2. **calculate_confidence** - è¨ˆç®—è©•åˆ†ä¿¡å¿ƒåº¦
3. **generate_feedback** - ã€æœ€çµ‚æ­¥é©Ÿã€‘ç”Ÿæˆè©•åˆ†çµæœ
4. **search_reference** - [å¯é¸] æœå°‹åƒè€ƒè³‡æ–™ï¼ˆåƒ…ç•¶æœ‰ä¸Šå‚³åƒè€ƒæ–‡ä»¶æ™‚ä½¿ç”¨ï¼‰
5. **check_similarity** - [å¯é¸] æª¢æŸ¥æŠ„è¥²ï¼ˆåƒ…ç•¶éœ€è¦æ™‚ä½¿ç”¨ï¼‰

## ğŸ§  å³æ™‚æ€è€ƒè¦æ±‚ï¼ˆThinking Aloud Protocolï¼‰

**æ¯æ¬¡ä½¿ç”¨å·¥å…·å‰ï¼Œå…ˆç”¨ think_aloud é€²è¡Œ Metacognitive Verbalizationï¼ˆå¾Œè¨­èªçŸ¥å£èªåŒ–ï¼‰ã€‚**

åƒè³‡æ·±æ•™å¸«æ‰¹æ”¹ä½œæ¥­æ™‚çš„å°ˆæ¥­è§€å¯Ÿï¼š

âœ… å¥½çš„ç¯„ä¾‹ï¼ˆåƒå°ˆæ¥­æ•™å¸«ï¼‰ï¼š
- ã€ŒCohesion æœ‰å•é¡Œï¼Œé€™è£¡ç¼ºå°‘ Transitional Phraseï¼Œå°è‡´æ®µè½ä¹‹é–“ Coherence ä¸è¶³...ã€
- ã€Œå¾ SOLO ä¾†çœ‹ï¼Œé€™ç¯‡åœç•™åœ¨ Multistructural Levelï¼Œåªæ˜¯åˆ—èˆ‰æƒ³æ³•ï¼Œç¼ºä¹ Integration...ã€
- ã€ŒSyntactic Complexity åä½ï¼Œå…¨æ–‡éƒ½æ˜¯ Simple Sentencesï¼Œéœ€è¦æ›´å¤š Subordinate Clauses...ã€
- ã€Œé€™å€‹ Evidence å¤ª Anecdotalï¼Œç¼ºä¹ Specificity å’Œ Credibility...ã€

âŒ ä¸å¥½çš„ç¯„ä¾‹ï¼ˆåƒæ©Ÿå™¨äººï¼‰ï¼š
- ã€Œæˆ‘å°‡ä½¿ç”¨ evaluate_subtrait ä¾†åˆ†æå¥å­çµæ§‹...ã€
- ã€Œç¾åœ¨é€²å…¥ Phase 2 è©•åˆ†éšæ®µ...ã€

## å»ºè­°æµç¨‹ (3-Step Process)
1. **Hattie's Analysis** â†’ think_aloud (Feed Up/Back/Forward)
2. **Confidence Check** â†’ calculate_confidence
3. **Final Output** â†’ generate_feedback

## âš ï¸ å¼·åˆ¶çµæŸè¦å‰‡ï¼ˆéå¸¸é‡è¦ï¼ï¼‰

ç•¶ä½ èª¿ç”¨ **calculate_confidence** å¾Œï¼Œä½ å¿…é ˆ**ç«‹å³**èª¿ç”¨ **generate_feedback**ã€‚

**ç¦æ­¢åœ¨ calculate_confidence ä¹‹å¾Œèª¿ç”¨ä»»ä½•å…¶ä»–å·¥å…·ï¼**

é †åºå¿…é ˆæ˜¯ï¼š
\`\`\`
calculate_confidence â†’ generate_feedbackï¼ˆçµæŸï¼‰
\`\`\`

å¦‚æœä½ ä¸éµå®ˆé€™å€‹è¦å‰‡ï¼Œè©•åˆ†å°‡å¤±æ•—ã€‚
`;

  const relevanceCheck = `
## Task Relevance Checkï¼ˆä»»å‹™ç›¸é—œæ€§æª¢æŸ¥ï¼‰

åœ¨è©•åˆ†å‰ï¼Œå¿…é ˆé€²è¡Œ Alignment Checkï¼š
- **Content Validity**ï¼šä½œæ¥­å…§å®¹æ˜¯å¦èˆ‡ Task Prompt ç›¸é—œï¼Ÿ
- **Language Appropriateness**ï¼šä½œæ¥­èªè¨€æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼Ÿ

å¦‚æœåˆ¤å®šç‚º Off-Topic Responseï¼ˆé›¢é¡Œå›æ‡‰ï¼‰ï¼š
1. åœ¨æ€è€ƒä¸­ä½¿ç”¨ SOLO è¡“èªï¼šã€Œæ­¤å›æ‡‰ç‚º Prestructural Level - å®Œå…¨é›¢é¡Œã€
2. æ‰€æœ‰è©•åˆ†é …ç›®çµ¦ 0 åˆ†ï¼ˆNo Creditï¼‰
3. åœ¨ Diagnostic Feedback ä¸­æ¸…æ¥šèªªæ˜ Task Alignment å•é¡Œ

## å®Œæ•´è©•é‡æµç¨‹ (Complete Assessment Procedure)

ç„¡è«–ä½œæ¥­å“è³ªå¦‚ä½•ï¼Œéƒ½å¿…é ˆå®Œæˆå®Œæ•´çš„ Assessment Cycleï¼š

1. **Initial Reading** - é€²è¡Œ Holistic First Impression
2. **Hattie's Analysis** - ä½¿ç”¨ think_aloud é€²è¡Œ Feed Up/Back/Forward åˆ†æ
3. **Confidence Assessment** - èª¿ç”¨ calculate_confidence è©•ä¼° Inter-Rater Reliability æ¨¡æ“¬
4. **Feedback Generation** - èª¿ç”¨ generate_feedback ç”¢å‡º Summative & Diagnostic Feedback

âš ï¸ ä¸è¦è·³éæ­¥é©Ÿï¼å®Œæ•´çš„ Assessment Documentation æ˜¯å°ˆæ¥­è©•é‡çš„åŸºæœ¬è¦æ±‚ã€‚
é€™ç¢ºä¿äº† Scoring Transparency å’Œ Accountabilityã€‚
`;

  if (isDirectMode) {
    return `${baseRole}\n${assignmentInfo}\n${rubricInfo}\n${coreInstructions}\n${relevanceCheck}`;
  }

  return `${baseRole}\n${assignmentInfo}\n${rubricInfo}\n${coreInstructions}\n${toolGuidance}\n${relevanceCheck}`;
}

// ============================================================================
// FALLBACK: Build result from steps when generate_feedback wasn't called
// ============================================================================

function buildFallbackResultFromSteps(steps: AgentStep[], criteria: ParsedCriterion[]): any | null {
  logger.warn('[Agent Fallback] 3-Step Process interrupted. No intermediate scores available.');

  // In the new 3-step process, scores are only generated in the final step.
  // If we are here, it means generate_feedback was not called or failed.

  return {
    totalScore: 0,
    maxScore: criteria.reduce((sum, c) => sum + c.maxScore, 0),
    overallFeedback: 'è©•åˆ†éç¨‹æœªæ­£å¸¸å®Œæˆï¼ˆ3-Step Process Interruptedï¼‰ã€‚è«‹é‡æ–°å˜—è©¦ã€‚',
    strengths: ['ç„¡æ³•åˆ†æ'],
    improvements: ['è«‹é‡æ–°æäº¤'],
    criteriaScores: criteria.map((c) => ({
      criteriaId: c.criteriaId,
      name: c.name,
      score: 0,
      maxScore: c.maxScore,
      evidence: 'è©•åˆ†ä¸­æ–·',
      analysis: 'è©•åˆ†ä¸­æ–·',
      justification: 'Process interrupted before generate_feedback',
    })),
    reasoning: 'The agent failed to complete the grading process.',
  };
}

// ============================================================================
// STOP CONDITION: When generate_feedback is called
// ============================================================================

function createStopCondition(maxSteps: number) {
  return (params: { steps: any[] }) => {
    // Stop if generate_feedback was called
    for (const step of params.steps) {
      if (step.toolCalls) {
        for (const call of step.toolCalls) {
          if (call.toolName === 'generate_feedback') {
            logger.info('[Agent] Stop: generate_feedback called');
            return true;
          }
        }
      }
    }

    // Safety: stop if max steps reached
    if (params.steps.length >= maxSteps) {
      logger.warn('[Agent] Stop: max steps reached', { steps: params.steps.length });
      return true;
    }

    return false;
  };
}

// ============================================================================
// DIRECT GRADING SCHEMA
// ============================================================================

const DirectGradingSchema = z.object({
  reasoning: z.string().describe('å®Œæ•´çš„è©•åˆ†æ¨ç†éç¨‹ï¼ŒåŒ…å«å°æ¯å€‹é …ç›®çš„åˆ†æ'),
  messageToStudent: z.string().describe('çµ¦å­¸ç”Ÿçš„å‹å–„å›é¥‹ï¼Œèªæ°£æº«æš–'),
  topPriority: z.string().describe('å­¸ç”Ÿæœ€éœ€è¦æ”¹é€²çš„ä¸€ä»¶äº‹'),
  encouragement: z.string().describe('çµ¦å­¸ç”Ÿçš„é¼“å‹µ'),
  criteriaScores: z.array(
    z.object({
      criteriaId: z.string(),
      name: z.string(),
      score: z.number().describe('åˆ†æ•¸'),
      maxScore: z.number(),
      evidence: z.string().describe('åŸæ–‡è­‰æ“š'),
      analysis: z.string().optional().describe('çµ¦å­¸ç”Ÿçš„å»ºè­°'),
      justification: z.string().optional().describe('çµ¦æ•™å¸«çš„ç†ç”±'),
    })
  ),
  overallObservation: z.string().describe('æ•´é«”è§€å¯Ÿ'),
  strengths: z.array(z.string()).optional().describe('å„ªé»åˆ—è¡¨'),
  improvements: z.array(z.string()).optional().describe('æ”¹é€²å»ºè­°åˆ—è¡¨'),
});

// ============================================================================
// MAIN EXECUTOR: True Agent Pattern
// ============================================================================

export async function executeGradingAgent(params: AgentGradingParams): Promise<AgentGradingResult> {
  const startTime = Date.now();
  const steps: AgentStep[] = [];
  const healthTracker = getKeyHealthTracker();
  let selectedKeyId: string | null = null;

  try {
    logger.info('[Agent] Starting autonomous grading', {
      resultId: params.resultId,
      rubricName: params.rubricName,
      hasAssignmentTitle: !!params.assignmentTitle,
    });

    // 1. Setup Model (Google Generative AI)
    let model: any;

    // Google Generative AI - ä½¿ç”¨ key rotation
    logger.info('[Agent] Using Google Generative AI provider');

    // Flexible key detection (supports 1, 2, or 3 keys)
    const availableKeyIds = ['1'];
    if (process.env.GEMINI_API_KEY2) availableKeyIds.push('2');
    if (process.env.GEMINI_API_KEY3) availableKeyIds.push('3');

    selectedKeyId = await healthTracker.selectBestKey(availableKeyIds);
    if (!selectedKeyId) throw new Error('All Gemini API keys are throttled');

    const apiKey =
      selectedKeyId === '1'
        ? process.env.GEMINI_API_KEY
        : selectedKeyId === '2'
          ? process.env.GEMINI_API_KEY2
          : process.env.GEMINI_API_KEY3;
    if (!apiKey) throw new Error(`API key not found for keyId: ${selectedKeyId}`);

    model = createGeminiModel(apiKey);

    // 2. Optimize Rubric
    let effectiveCriteria = params.criteria;
    try {
      effectiveCriteria = await optimizeRubricWithLLM(model, params.rubricName, params.criteria);
    } catch (e) {
      logger.warn('[Agent] Rubric optimization failed, using original', e);
    }

    // 3. Build Context
    const ctx: GradingContext = {
      rubricName: params.rubricName,
      criteria: effectiveCriteria,
      content: params.content,
      fileName: params.fileName,
      referenceDocuments: params.referenceDocuments,
      assignmentTitle: params.assignmentTitle,
      assignmentDescription: params.assignmentDescription,
      assignmentType: params.assignmentType,
      userLanguage: params.userLanguage,
    };

    // CHECK FOR DIRECT GRADING MODE
    if (params.useDirectGrading) {
      logger.info('[Agent] Executing Direct Grading Mode (Manual Branch)');
      const systemPrompt = buildGradingSystemPrompt(ctx, true);
      const userMessage = `è«‹è©•åˆ†ä»¥ä¸‹å­¸ç”Ÿä½œæ¥­ï¼š

    ${params.assignmentTitle ? `ã€ä½œæ¥­æ¨™é¡Œã€‘${params.assignmentTitle}` : ''}
    ${params.assignmentDescription ? `ã€ä½œæ¥­èªªæ˜ã€‘${params.assignmentDescription}` : ''}
    ã€å­¸ç”Ÿä½œæ¥­å…§å®¹ã€‘
    ${params.content}

    è«‹ç›´æ¥è¼¸å‡ºè©•åˆ†çµæœ JSONã€‚`;

      try {
        const { object: result, usage, providerMetadata } = await generateObject({
          model,
          schema: DirectGradingSchema,
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userMessage },
          ],
          providerOptions: {
            google: {
              thinkingConfig: {
                includeThoughts: true,
                thinkingLevel: 'high',
              },
              safetySettings: [
                { category: 'HARM_CATEGORY_HATE_SPEECH', threshold: 'BLOCK_ONLY_HIGH' },
                { category: 'HARM_CATEGORY_DANGEROUS_CONTENT', threshold: 'BLOCK_ONLY_HIGH' },
                { category: 'HARM_CATEGORY_HARASSMENT', threshold: 'BLOCK_ONLY_HIGH' },
                { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold: 'BLOCK_ONLY_HIGH' },
              ],
            },
          },
        });

        // Capture Gemini Native Thinking
        let directThinking = '';
        const googleMetadata = providerMetadata?.google as any;
        if (googleMetadata?.thoughts) {
          directThinking = googleMetadata.thoughts as string;
          logger.info('[Agent] Captured Direct Mode Thinking', { length: directThinking.length });
        }

        // Construct a "fake" step for the direct execution to fit the AgentGradingResult structure
        const steps: AgentStep[] = [
          {
            stepNumber: 1,
            toolName: 'direct_grading',
            reasoning: directThinking || result.reasoning, // Prefer native thinking if available
            toolOutput: result,
            durationMs: Date.now() - startTime,
            timestamp: new Date(),
          },
        ];

        // Map to AIGradingResult format to satisfy type requirements
        const mappedData = {
          breakdown: result.criteriaScores.map((s: any) => ({
            criteriaId: s.criteriaId,
            name: s.name,
            score: s.score,
            feedback: s.analysis || s.justification || '',
          })),
          overallFeedback: result.messageToStudent || result.overallObservation,
          summary: result.overallObservation,
        };

        return {
          success: true,
          data: mappedData,
          steps,
          confidenceScore: 1.0, // Direct mode assumes high confidence or N/A
          requiresReview: false,
          totalTokens: usage?.totalTokens || 0,
          executionTimeMs: Date.now() - startTime,
        };
      } catch (error) {
        logger.error('[Agent] Direct grading failed', error);
        throw error;
      }
    }

    // 4. Create Tools (ALL tools available at once)
    const tools = createAgentTools({
      referenceDocuments: params.referenceDocuments,
      currentContent: params.content,
      assignmentType: params.assignmentType,
      sessionId: params.sessionId,
    });

    // 5. Create Agent with ToolLoopAgent
    const agent = new ToolLoopAgent({
      model,
      instructions: buildGradingSystemPrompt(ctx),
      tools,
      stopWhen: createStopCondition(15), // Max 15 steps or until feedback generated
      prepareStep: async ({ stepNumber, steps: previousSteps }) => {
        logger.debug('[Agent] prepareStep', { stepNumber, previousSteps: previousSteps.length });

        // Record previous step for UI transparency
        if (previousSteps.length > 0) {
          const lastStep = previousSteps[previousSteps.length - 1];
          const toolsUsed = lastStep.toolCalls?.map((c) => c.toolName) || [];

          // DEBUG: Log the full content structure
          logger.info('[Agent] Step content structure', {
            stepNumber: previousSteps.length,
            contentLength: lastStep.content?.length || 0,
            contentTypes: lastStep.content?.map((p: any) => p.type) || [],
            reasoningArrayLength: lastStep.reasoning?.length || 0,
            reasoningParts:
              lastStep.reasoning?.map((r: any) => ({
                type: r.type,
                hasText: !!r.text,
                textPreview: r.text?.substring(0, 50),
              })) || [],
          });

          // Capture reasoning from multiple sources:
          // 1. reasoning array - contains parts with type "reasoning"
          // 2. reasoningText - computed from reasoning array
          // 3. text - regular text output
          let reasoning = '';

          // Try to get from reasoning array (structured parts)
          if (lastStep.reasoning && lastStep.reasoning.length > 0) {
            reasoning = lastStep.reasoning
              .map((r: any) => r.text)
              .filter(Boolean)
              .join('\n');
            logger.debug('[Agent] Captured from reasoning array', {
              partsCount: lastStep.reasoning.length,
              combinedLength: reasoning.length,
            });
          }

          // Fallback to reasoningText (computed string)
          if (!reasoning && lastStep.reasoningText) {
            reasoning = lastStep.reasoningText;
            logger.debug('[Agent] Captured reasoningText', {
              length: reasoning.length,
              preview: reasoning.substring(0, 100),
            });
          }

          // Also capture regular text output
          if (lastStep.text) {
            if (reasoning) {
              reasoning += '\n\n' + lastStep.text;
            } else {
              reasoning = lastStep.text;
            }
          }

          // Log what we captured for debugging
          const hasReasoningArray = (lastStep.reasoning?.length || 0) > 0;
          const hasReasoningText = !!lastStep.reasoningText;
          const hasText = !!lastStep.text;
          const reasoningPreview = reasoning.substring(0, 200);

          logger.info(
            `[Agent] Step ${previousSteps.length} completed: ` +
              `hasReasoningArray=${hasReasoningArray}, hasReasoningText=${hasReasoningText}, hasText=${hasText}, ` +
              `tools=[${toolsUsed.join(',')}], ` +
              `reasoning="${reasoningPreview}..."`
          );

          if (reasoning || toolsUsed.length > 0) {
            steps.push({
              stepNumber: previousSteps.length,
              reasoning: reasoning,
              toolName: toolsUsed[0],
              toolInput: lastStep.toolCalls?.[0]?.input,
              toolOutput: lastStep.toolResults?.[0]?.output,
              durationMs: 0,
              timestamp: new Date(),
            });
          }
        }

        // Soft guidance based on progress (NO tool locking)
        const thinkReminder = '\n\nâš ï¸ åœ¨ä½¿ç”¨å·¥å…·å‰ï¼Œå…ˆç”¨ think_aloud èªªå‡ºä½ çš„æƒ³æ³•ã€‚ä¸è¦æåŠå·¥å…·åç¨±ï¼';

        // Check what tools have been called so far
        const toolsCalled = steps.map((s) => s.toolName).filter(Boolean);
        const hasCalledConfidence = toolsCalled.includes('calculate_confidence');
        const hasCalledThinkAloud = toolsCalled.includes('think_aloud');

        logger.debug('[Agent] Tools called so far', {
          stepNumber,
          toolsCalled: toolsCalled.join(', '),
          hasCalledConfidence,
          hasCalledThinkAloud,
        });

        let guidance = '';
        if (hasCalledConfidence) {
          // Force generate_feedback immediately after calculate_confidence
          guidance = `
          ã€å¼·åˆ¶çµæŸã€‘

          ä½ å·²ç¶“èª¿ç”¨äº† calculate_confidenceï¼Œç¾åœ¨å¿…é ˆ**ç«‹å³**èª¿ç”¨ generate_feedbackï¼

          ä¸è¦å†èª¿ç”¨å…¶ä»–å·¥å…·ï¼ä¸è¦è¼¸å‡ºç©ºå…§å®¹ï¼

          è«‹ç›´æ¥èª¿ç”¨ generate_feedbackï¼ŒåŒ…å«ï¼š
          - reasoning: å®Œæ•´çš„è©•åˆ†æ¨ç†
          - totalScore / maxScore: ç¸½åˆ†
          - criteriaScores: æ¯é …åˆ†æ•¸
          - overallFeedback: æ•´é«”è©•èª
          - strengths / improvements: å„ªç¼ºé»
          `;
        } else if (stepNumber >= 5) {
          // Force completion if taking too long (should be done in 3 steps)
          guidance = `
          ã€å³å°‡è¶…æ™‚ã€‘ä½ å·²ç¶“åŸ·è¡Œäº† ${stepNumber} å€‹æ­¥é©Ÿã€‚

          è«‹ç«‹å³å®Œæˆè©•åˆ†ï¼š
          1. å¦‚æœé‚„æ²’èª¿ç”¨ calculate_confidenceï¼Œç¾åœ¨èª¿ç”¨
          2. ç„¶å¾Œç«‹å³èª¿ç”¨ generate_feedback è¼¸å‡ºçµæœ`;
        } else if (stepNumber === 0) {
          guidance =
            '\n\nã€æ­¥é©Ÿ 1/3ã€‘è«‹ä½¿ç”¨ think_aloud é€²è¡Œå®Œæ•´çš„ Hattie & Timperley åˆ†æ (Feed Up/Back/Forward)ã€‚' +
            thinkReminder;
        } else if (hasCalledThinkAloud && !hasCalledConfidence) {
          guidance = '\n\nã€æ­¥é©Ÿ 2/3ã€‘åˆ†æå®Œæˆã€‚è«‹èª¿ç”¨ calculate_confidence è©•ä¼°ä¿¡å¿ƒåº¦ã€‚';
        } else {
          guidance = thinkReminder;
        }

        return {
          providerOptions: {
            google: {
              thinkingConfig: {
                includeThoughts: true,
                thinkingLevel: 'high',
              },
              safetySettings: [
                { category: 'HARM_CATEGORY_HATE_SPEECH', threshold: 'BLOCK_ONLY_HIGH' },
                { category: 'HARM_CATEGORY_DANGEROUS_CONTENT', threshold: 'BLOCK_ONLY_HIGH' },
                { category: 'HARM_CATEGORY_HARASSMENT', threshold: 'BLOCK_ONLY_HIGH' },
                { category: 'HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold: 'BLOCK_ONLY_HIGH' },
              ],
            },
          },
          ...(guidance ? { system: buildGradingSystemPrompt(ctx) + guidance } : {}),
        };
      },
    });

    // 6. Execute Agent
    const userMessage = `è«‹è©•åˆ†ä»¥ä¸‹å­¸ç”Ÿä½œæ¥­ï¼š

    ${params.assignmentTitle ? `ã€ä½œæ¥­æ¨™é¡Œã€‘${params.assignmentTitle}` : ''}
    ${params.assignmentDescription ? `ã€ä½œæ¥­èªªæ˜ã€‘${params.assignmentDescription}` : ''}
    ã€å­¸ç”Ÿä½œæ¥­å…§å®¹ã€‘
    ï¼ˆæ³¨æ„ï¼šé€™æ˜¯çœŸå¯¦å­¸ç”Ÿçš„æäº¤ï¼Œè«‹ç›´æ¥è©•åˆ†ï¼Œä¸è¦å‡è¨­å®ƒæ˜¯ç¯„ä¾‹ï¼‰
    ${params.content}
    è«‹ä½¿ç”¨é©ç•¶çš„å·¥å…·é€²è¡Œè©•åˆ†ï¼Œå®Œæˆå¾Œèª¿ç”¨ generate_feedback è¼¸å‡ºçµæœã€‚`;

    logger.info('[Agent] Executing', {
      contentLength: params.content.length,
      hasTitle: !!params.assignmentTitle,
    });

    const result = await agent.generate({
      messages: [{ role: 'user', content: userMessage }],
    });

    // Log overall result structure for debugging
    const stepsWithReasoning = result.steps.filter((s) => s.reasoningText).length;
    const stepsWithText = result.steps.filter((s) => s.text).length;
    const stepsWithReasoningArray = result.steps.filter((s) => (s.reasoning?.length || 0) > 0).length;
    logger.info(
      `[Agent] Generation completed: totalSteps=${result.steps.length}, ` +
        `stepsWithReasoningArray=${stepsWithReasoningArray}, ` +
        `stepsWithReasoningText=${stepsWithReasoning}, stepsWithText=${stepsWithText}`
    );

    // DEBUG: Log ALL keys at result level to find thinking
    const resultKeys = Object.keys(result);
    logger.debug(`[Agent] Result object keys: ${resultKeys.join(', ')}`);

    // Check if thinking is at result level - DETAILED OUTPUT
    if ((result as any).reasoning) {
      const reasoning = (result as any).reasoning;
      logger.info(`[Agent] âœ¨ Result.reasoning FOUND! Type: ${typeof reasoning}, IsArray: ${Array.isArray(reasoning)}`);
      if (Array.isArray(reasoning)) {
        logger.info(`[Agent] âœ¨ Result.reasoning array length: ${reasoning.length}`);
        reasoning.forEach((r: any, i: number) => {
          logger.info(
            `[Agent] âœ¨ Result.reasoning[${i}]: type=${r?.type}, text=${JSON.stringify(r?.text || r)?.substring(0, 300)}`
          );
        });
      } else if (typeof reasoning === 'string') {
        logger.info(`[Agent] âœ¨ Result.reasoning string: ${reasoning.substring(0, 500)}`);
      } else {
        logger.info(`[Agent] âœ¨ Result.reasoning object: ${JSON.stringify(reasoning).substring(0, 500)}`);
      }
    }
    if ((result as any).reasoningText) {
      logger.info(`[Agent] âœ¨ Result.reasoningText: ${(result as any).reasoningText.substring(0, 500)}`);
    }
    if ((result as any).providerMetadata) {
      const pm = (result as any).providerMetadata;
      logger.info(`[Agent] Result.providerMetadata keys: ${Object.keys(pm).join(', ')}`);
      // Check for google-specific metadata
      if (pm.google) {
        logger.info(`[Agent] âœ¨ providerMetadata.google: ${JSON.stringify(pm.google).substring(0, 500)}`);
      }
    }

    // Log each step's content structure - DETAILED DEBUG
    result.steps.forEach((step, idx) => {
      // Log basic structure
      logger.info(
        `[Agent] Final Step ${idx} structure: ` +
          `contentTypes=[${step.content?.map((p: any) => p.type).join(',') || 'empty'}], ` +
          `reasoningArrayLen=${step.reasoning?.length || 0}, ` +
          `reasoningText=${step.reasoningText?.substring(0, 50) || 'null'}, ` +
          `text=${step.text?.substring(0, 50) || 'null'}`
      );

      // Log ALL keys in step object to find where thinking might be hiding
      const stepKeys = Object.keys(step);
      logger.debug(`[Agent] Step ${idx} all keys: ${stepKeys.join(', ')}`);

      // Check for providerMetadata (where Gemini thinking might be)
      if ((step as any).providerMetadata) {
        const pm = (step as any).providerMetadata;
        const pmKeys = Object.keys(pm);
        if (pmKeys.length > 0) {
          logger.info(`[Agent] Step ${idx} providerMetadata keys: ${pmKeys.join(', ')}`);
          if (pm.google) {
            logger.info(
              `[Agent] âœ¨ Step ${idx} providerMetadata.google: ${JSON.stringify(pm.google).substring(0, 500)}`
            );
          }
        }
      }

      // Check response.body for raw Gemini response (thinking might be here!)
      if ((step as any).response?.body) {
        const body = (step as any).response.body;

        // Log the raw body structure to find where thoughts are
        logger.debug(`[Agent] Step ${idx} response.body keys: ${Object.keys(body || {}).join(', ')}`);

        // Look for candidates[0].content.parts with thinking
        if (body.candidates?.[0]?.content?.parts) {
          const parts = body.candidates[0].content.parts;
          logger.info(`[Agent] Step ${idx} has ${parts.length} parts in response.body`);

          // Log ALL parts to see their structure
          parts.forEach((p: any, pIdx: number) => {
            const partKeys = Object.keys(p);
            logger.debug(`[Agent] Step ${idx} body.part[${pIdx}] keys: ${partKeys.join(', ')}`);

            // Check for thought flag or thinking content
            if (p.thought === true || p.thought === 'true') {
              logger.info(`[Agent] âœ¨âœ¨âœ¨ Step ${idx} FOUND THOUGHT PART! text: ${p.text?.substring(0, 500)}`);
            }
            if (p.thinkingContent) {
              logger.info(
                `[Agent] âœ¨âœ¨âœ¨ Step ${idx} FOUND thinkingContent! ${JSON.stringify(p.thinkingContent).substring(0, 500)}`
              );
            }
          });
        }

        // Check for thoughts at various levels
        if (body.thoughts) {
          logger.info(`[Agent] âœ¨âœ¨âœ¨ Step ${idx} body.thoughts: ${JSON.stringify(body.thoughts).substring(0, 500)}`);
        }
        if (body.candidates?.[0]?.thoughts) {
          logger.info(
            `[Agent] âœ¨âœ¨âœ¨ Step ${idx} candidates[0].thoughts: ${JSON.stringify(body.candidates[0].thoughts).substring(0, 500)}`
          );
        }
        if (body.candidates?.[0]?.thinkingContent) {
          logger.info(
            `[Agent] âœ¨âœ¨âœ¨ Step ${idx} candidates[0].thinkingContent: ${JSON.stringify(body.candidates[0].thinkingContent).substring(0, 500)}`
          );
        }
      }

      // Check each content part's providerMetadata
      if (step.content && step.content.length > 0) {
        step.content.forEach((part: any, partIdx: number) => {
          if (part.providerMetadata) {
            const partPm = part.providerMetadata;
            const partPmKeys = Object.keys(partPm);
            if (partPmKeys.length > 0) {
              logger.debug(`[Agent] Step ${idx} content[${partIdx}] providerMetadata keys: ${partPmKeys.join(', ')}`);
              if (partPm.google) {
                logger.info(
                  `[Agent] âœ¨ Step ${idx} content[${partIdx}] providerMetadata.google: ${JSON.stringify(partPm.google).substring(0, 300)}`
                );
              }
            }
          }
        });
      }
    });

    // 7. Extract Final Result and capture ALL reasoning from steps
    let finalResult: any = null;
    let confidenceData: any = null;
    let feedbackReasoning: string = ''; // å¾ generate_feedback input æå–çš„æ¨ç†
    let directThinking: string = ''; // å¾ Direct Mode çš„ providerMetadata æå–çš„æ€è€ƒ

    // Also capture any reasoning we might have missed in prepareStep
    for (const step of result.steps) {
      // Capture reasoning from this step if not already captured
      const stepReasoning = step.reasoningText || step.text || '';
      if (stepReasoning) {
        logger.debug('[Agent] Final step reasoning', {
          hasReasoningText: !!step.reasoningText,
          hasText: !!step.text,
          preview: stepReasoning.substring(0, 100),
        });
      }

      // Capture Gemini Native Thinking (Direct Mode)
      if ((step as any).providerMetadata?.google?.thoughts) {
        directThinking = (step as any).providerMetadata.google.thoughts;
      }

      if (step.toolCalls) {
        for (let i = 0; i < step.toolCalls.length; i++) {
          const call = step.toolCalls[i];
          if (call.toolName === 'generate_feedback') {
            finalResult = step.toolResults?.[i]?.output;
            // å¾ tool input æå– reasoningï¼ˆé€™æ˜¯å¼·åˆ¶æ¬„ä½ï¼‰
            const toolInput = call.input as any;
            if (toolInput?.reasoning) {
              feedbackReasoning = toolInput.reasoning;
              logger.info('[Agent] Extracted reasoning from generate_feedback input', {
                reasoningLength: feedbackReasoning.length,
                preview: feedbackReasoning.substring(0, 200),
              });
            }
          }
          if (call.toolName === 'calculate_confidence') {
            confidenceData = step.toolResults?.[i]?.output;
          }
        }
      }
    }

    if (!finalResult) {
      logger.warn('[Agent] generate_feedback was not called, building fallback result from steps...');

      // Fallback: Try to build a partial result (though likely empty in 3-step process)
      finalResult = buildFallbackResultFromSteps(steps, params.criteria);

      if (!finalResult) {
        throw new Error('Agent completed but did not call generate_feedback and fallback failed');
      }

      logger.info('[Agent] Fallback result built successfully', {
        totalScore: finalResult.totalScore,
        maxScore: finalResult.maxScore,
      });
    }

    // 8. Build Response
    const executionTimeMs = Date.now() - startTime;
    await healthTracker.recordSuccess(selectedKeyId, executionTimeMs);

    // Ensure finalResult has breakdown (map from criteriaScores if needed)
    if (finalResult && finalResult.criteriaScores && !finalResult.breakdown) {
      finalResult.breakdown = finalResult.criteriaScores.map((c: any) => ({
        criteriaId: c.criteriaId,
        name: c.name,
        score: c.score,
        feedback: c.analysis || c.justification || '',
      }));
    }

    // Ensure overallFeedback exists
    if (
      finalResult &&
      !finalResult.overallFeedback &&
      (finalResult.messageToStudent || finalResult.overallObservation)
    ) {
      finalResult.overallFeedback = finalResult.messageToStudent || finalResult.overallObservation;
    }

    // Add reasoning step if we captured it from generate_feedback
    if (feedbackReasoning) {
      steps.push({
        stepNumber: steps.length + 1,
        reasoning: feedbackReasoning,
        toolName: 'generate_feedback',
        durationMs: 0,
        timestamp: new Date(),
      });
    } else if (directThinking) {
      // If we have native thinking but no explicit reasoning field (Direct Mode fallback)
      steps.push({
        stepNumber: steps.length + 1,
        reasoning: directThinking,
        toolName: 'direct_grading',
        durationMs: 0,
        timestamp: new Date(),
      });
    }

    // Add final summary step
    steps.push({
      stepNumber: steps.length + 1,
      reasoning: `è©•åˆ†å®Œæˆã€‚ç¸½åˆ†ï¼š${finalResult.totalScore}/${finalResult.maxScore}`,
      durationMs: 0,
      timestamp: new Date(),
    });

    logger.info('[Agent] Grading completed', {
      totalSteps: result.steps.length,
      totalScore: finalResult.totalScore,
      maxScore: finalResult.maxScore,
      executionTimeMs,
    });

    return {
      success: true,
      data: finalResult,
      steps,
      confidenceScore: confidenceData?.confidenceScore ?? 0.8,
      requiresReview: confidenceData?.shouldReview ?? false,
      totalTokens: 0,
      executionTimeMs,
    };
  } catch (error) {
    logger.error('[Agent] Grading failed', error);

    // Report failure to health tracker
    if (selectedKeyId) {
      const errorMessage = error instanceof Error ? error.message : String(error);
      let errorType: ErrorType = 'other';

      if (errorMessage.includes('429') || errorMessage.includes('quota') || errorMessage.includes('limit')) {
        errorType = 'rate_limit';
      } else if (errorMessage.includes('503') || errorMessage.includes('overloaded')) {
        errorType = 'overloaded';
      }

      await healthTracker.recordFailure(selectedKeyId, errorType, errorMessage);
    }

    return {
      success: false,
      steps,
      confidenceScore: 0,
      requiresReview: true,
      totalTokens: 0,
      executionTimeMs: Date.now() - startTime,
      error: error instanceof Error ? error.message : String(error),
    };
  }
}

/**
 * Check if Agent grading is enabled
 */
export function isAgentGradingEnabled(): boolean {
  return process.env.USE_AGENT_GRADING === 'true';
}
