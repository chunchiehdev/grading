# AI SDK æ¨¡å‹ä½¿ç”¨èªªæ˜

## ğŸ“Š æ¨¡å‹å°ç…§è¡¨

| ç³»çµ± | Provider | æ¨¡å‹ | æª”æ¡ˆä½ç½® | è¡Œè™Ÿ |
|------|----------|------|----------|------|
| **æ–°ç³»çµ± (AI SDK)** | Gemini | `gemini-2.5-flash` | `app/services/ai-sdk-provider.server.ts` | 167 |
| **æ–°ç³»çµ± (AI SDK)** | OpenAI (Fallback) | `gpt-4o-mini` | `app/services/ai-sdk-provider.server.ts` | 271 |
| **èˆŠç³»çµ±** | Gemini (Rotating) | `gemini-2.5-flash` | `app/services/gemini-rotating.server.ts` | 54 |
| **èˆŠç³»çµ±** | Gemini (Simple) | `gemini-2.5-flash` | `app/services/gemini-simple.server.ts` | 17 |
| **èˆŠç³»çµ±** | OpenAI (Fallback) | `gpt-4o-mini` | `app/services/openai-simple.server.ts` | 12 |

---

## ğŸ†• æ–°ç³»çµ± (AI SDK) - æ¨¡å‹é…ç½®

### 1. Gemini æ¨¡å‹é…ç½®

**æª”æ¡ˆ**: `app/services/ai-sdk-provider.server.ts`

**ä¸»è¦æ¨¡å‹**: `gemini-2.5-flash`

**ç¨‹å¼ç¢¼ä½ç½®**:
```typescript
// Line 155-172
const geminiProvider = createGoogleGenerativeAI({ apiKey });

const result = await generateObject({
  model: geminiProvider('gemini-2.5-flash'),  // â† Line 167
  schema: GradingResultSchema,
  prompt,
  temperature,  // é è¨­ 0.3
  maxRetries: 2,
});
```

**é…ç½®ç´°ç¯€**:
- **Temperature**: `0.3` (é è¨­å€¼ï¼Œåœ¨ `gradeWithGemini()` å‡½æ•¸åƒæ•¸ä¸­å®šç¾©)
- **Max Retries**: `2` (AI SDK å…§å»º retry)
- **Schema Validation**: ä½¿ç”¨ Zod schema (`GradingResultSchema`)
- **Output Format**: Type-safe structured output (è‡ªå‹• JSON é©—è­‰)

**èˆ‡èˆŠç³»çµ±çš„å·®ç•°**:
```diff
èˆŠç³»çµ± (gemini-rotating.server.ts:54):
- private model: string = 'gemini-2.5-flash';
+ æ‰‹å‹• JSON Schema å®šç¾©
+ æ‰‹å‹• response parsing
+ Temperature: 0.3
+ maxOutputTokens: 8192
+ thinkingConfig: { thinkingBudget: 8192 }

æ–°ç³»çµ± (ai-sdk-provider.server.ts:167):
+ model: geminiProvider('gemini-2.5-flash')
+ Zod schema è‡ªå‹•é©—è­‰
+ è‡ªå‹• response parsing
+ Temperature: 0.3 (ç›¸åŒ)
- æ²’æœ‰ maxOutputTokens (AI SDK è‡ªå‹•è™•ç†)
- æ²’æœ‰ thinkingConfig (AI SDK å¯èƒ½ä¸æ”¯æ´)
```

---

### 2. OpenAI æ¨¡å‹é…ç½® (Fallback)

**æª”æ¡ˆ**: `app/services/ai-sdk-provider.server.ts`

**Fallback æ¨¡å‹**: `gpt-4o-mini`

**ç¨‹å¼ç¢¼ä½ç½®**:
```typescript
// Line 260-276
const openaiProvider = createOpenAI({ apiKey });

const result = await generateObject({
  model: openaiProvider('gpt-4o-mini'),  // â† Line 271
  schema: GradingResultSchema,
  prompt,
  temperature,  // é è¨­ 0.1
  maxRetries: 2,
});
```

**é…ç½®ç´°ç¯€**:
- **Temperature**: `0.1` (é è¨­å€¼ï¼Œæ¯” Gemini æ›´ä¿å®ˆ)
- **Max Retries**: `2`
- **Schema Validation**: ä½¿ç”¨ç›¸åŒçš„ Zod schema
- **Output Format**: Type-safe structured output

**èˆ‡èˆŠç³»çµ±çš„å·®ç•°**:
```diff
èˆŠç³»çµ± (openai-simple.server.ts:12):
- private model: string = 'gpt-4o-mini';
+ æ‰‹å‹• prompt æ§‹å»º
+ response_format: { type: 'json_object' }
+ Temperature: 0.1
+ max_tokens: 4000

æ–°ç³»çµ± (ai-sdk-provider.server.ts:271):
+ model: openaiProvider('gpt-4o-mini')
+ Zod schema è‡ªå‹•é©—è­‰
+ è‡ªå‹• prompt æ§‹å»º
+ Temperature: 0.1 (ç›¸åŒ)
- æ²’æœ‰ max_tokens (AI SDK è‡ªå‹•è™•ç†)
```

---

## ğŸ”„ Fallback æµç¨‹

**æª”æ¡ˆ**: `app/services/ai-grader-sdk.server.ts`

**å®Œæ•´æµç¨‹** (Lines 66-173):
```typescript
async function gradeWithAI(params) {
  // Step 1: å˜—è©¦ Gemini
  const geminiResult = await gradeWithGemini({
    prompt,
    userId,
    resultId,
    temperature,  // é è¨­ 0.3
  });

  if (geminiResult.success) {
    return geminiResult;  // âœ… Gemini æˆåŠŸï¼Œç›´æ¥è¿”å›
  }

  // Step 2: Gemini å¤±æ•—ï¼Œfallback åˆ° OpenAI
  logger.info('Falling back to OpenAI', { userId, resultId });

  const openaiResult = await gradeWithOpenAI({
    prompt,
    userId,
    resultId,
    temperature,  // é è¨­ 0.1 (æœƒè¢« gradeWithOpenAI è¦†è“‹)
  });

  if (openaiResult.success) {
    return openaiResult;  // âœ… OpenAI æˆåŠŸ
  }

  // Step 3: å…©å€‹éƒ½å¤±æ•—
  return {
    success: false,
    error: 'Both Gemini and OpenAI providers failed',
    geminiError: geminiResult.error,
    openaiError: openaiResult.error,
  };
}
```

---

## ğŸ”§ å¦‚ä½•ä¿®æ”¹æ¨¡å‹

### ä¿®æ”¹ Gemini æ¨¡å‹

**ä½ç½®**: `app/services/ai-sdk-provider.server.ts:167`

```typescript
// ç•¶å‰
model: geminiProvider('gemini-2.5-flash'),

// ä¿®æ”¹ç‚ºå…¶ä»–æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼‰
model: geminiProvider('gemini-1.5-pro'),
// æˆ–
model: geminiProvider('gemini-2.0-flash-exp'),
```

**æ”¯æ´çš„ Gemini æ¨¡å‹**:
- `gemini-2.5-flash` (ç•¶å‰ä½¿ç”¨ï¼Œæœ€å¿«)
- `gemini-2.0-flash-exp` (å¯¦é©—ç‰ˆæœ¬)
- `gemini-1.5-pro` (æ›´å¼·å¤§ä½†è¼ƒæ…¢)
- `gemini-1.5-flash` (èˆŠç‰ˆ flash)

### ä¿®æ”¹ OpenAI æ¨¡å‹

**ä½ç½®**: `app/services/ai-sdk-provider.server.ts:271`

```typescript
// ç•¶å‰
model: openaiProvider('gpt-4o-mini'),

// ä¿®æ”¹ç‚ºå…¶ä»–æ¨¡å‹ï¼ˆä¾‹å¦‚ï¼‰
model: openaiProvider('gpt-4o'),
// æˆ–
model: openaiProvider('gpt-4-turbo'),
```

**æ”¯æ´çš„ OpenAI æ¨¡å‹**:
- `gpt-4o-mini` (ç•¶å‰ä½¿ç”¨ï¼Œä¾¿å®œå¿«é€Ÿ)
- `gpt-4o` (æ›´å¼·å¤§ä½†è¼ƒè²´)
- `gpt-4-turbo` (GPT-4 Turbo)
- `gpt-3.5-turbo` (æœ€ä¾¿å®œï¼Œä½†æ•ˆæœè¼ƒå·®)

### ä¿®æ”¹ Temperature

**Gemini Temperature** (`app/services/ai-sdk-provider.server.ts:147`):
```typescript
export async function gradeWithGemini(params: GradingParams): Promise<GradingResult> {
  const { prompt, userId, resultId, temperature = 0.3 } = params;
  //                                            ^^^ ä¿®æ”¹é€™è£¡
}
```

**OpenAI Temperature** (`app/services/ai-sdk-provider.server.ts:248`):
```typescript
export async function gradeWithOpenAI(params: GradingParams): Promise<GradingResult> {
  const { prompt, userId, resultId, temperature = 0.1 } = params;
  //                                            ^^^ ä¿®æ”¹é€™è£¡
}
```

---

## ğŸ“ˆ æ¨¡å‹ç‰¹æ€§å°æ¯”

### Gemini 2.5 Flash vs OpenAI GPT-4o-mini

| ç‰¹æ€§ | Gemini 2.5 Flash | GPT-4o-mini |
|------|------------------|-------------|
| **é€Ÿåº¦** | æ¥µå¿« (2-5ç§’) | å¿« (3-8ç§’) |
| **æˆæœ¬** | å…è²» (æœ‰ quota) | ä»˜è²» |
| **Context Length** | 128k tokens | 128k tokens |
| **Output Quality** | å„ªç§€ | å„ªç§€ |
| **Structured Output** | åŸç”Ÿæ”¯æ´ | åŸç”Ÿæ”¯æ´ |
| **Thinking Mode** | âœ… æ”¯æ´ (èˆŠç³»çµ±) | âŒ ä¸æ”¯æ´ |
| **API Stability** | ç©©å®š | éå¸¸ç©©å®š |
| **Rate Limit** | 8-10 RPM (å…è²») | æ ¹æ“šä»˜è²»æ–¹æ¡ˆ |

### æ–°èˆŠç³»çµ±é…ç½®å°æ¯”

| é…ç½®é … | èˆŠç³»çµ± (Gemini Rotating) | æ–°ç³»çµ± (AI SDK) |
|--------|--------------------------|-----------------|
| **Model** | `gemini-2.5-flash` | `gemini-2.5-flash` âœ… ç›¸åŒ |
| **Temperature** | `0.3` | `0.3` âœ… ç›¸åŒ |
| **Max Output Tokens** | `8192` | è‡ªå‹•è™•ç† (å¯èƒ½ä¸åŒ) |
| **Thinking Budget** | `8192` | âŒ ä¸æ”¯æ´ |
| **Response Format** | æ‰‹å‹• JSON Schema | Zod Schema è‡ªå‹•é©—è­‰ |
| **Schema Validation** | æ‰‹å‹• | è‡ªå‹• âœ… |
| **Error Handling** | æ‰‹å‹• try-catch | AI SDK + æ‰‹å‹• fallback |

---

## âš ï¸ é‡è¦æ³¨æ„äº‹é …

### 1. Thinking Mode å¯èƒ½ä¸å¯ç”¨

**èˆŠç³»çµ±** (`gemini-rotating.server.ts`):
```typescript
thinkingConfig: {
  thinkingBudget: 8192,
}
```

**æ–°ç³»çµ±**: AI SDK å¯èƒ½ä¸æ”¯æ´ `thinkingConfig`

**å½±éŸ¿**:
- `thoughtSummary` å¯èƒ½æœƒæ˜¯ç©ºçš„æˆ–æ ¼å¼ä¸åŒ
- ä½†å¾æ‚¨çš„ log çœ‹ï¼Œä»ç„¶æœ‰ thought summaryï¼š
  ```
  ğŸ’­ Thought summary available (205 chars)
  ```
  é€™è¡¨ç¤º Gemini å¯èƒ½ä»ç„¶è¿”å›äº†æ€è€ƒéç¨‹

### 2. Token Limits

**èˆŠç³»çµ±**:
- Gemini: `maxOutputTokens: 8192`
- OpenAI: `max_tokens: 4000`

**æ–°ç³»çµ±**:
- æ²’æœ‰æ˜ç¢ºè¨­å®šï¼Œç”± AI SDK è‡ªå‹•è™•ç†
- å¯èƒ½æœƒæœ‰ä¸åŒçš„ default limits

**å»ºè­°**: å¦‚æœé‡åˆ°å›æ‡‰è¢«æˆªæ–·çš„å•é¡Œï¼Œå¯èƒ½éœ€è¦æ‰‹å‹•è¨­å®š `maxTokens`

### 3. Cost Monitoring

**Gemini**:
- å…è²» tier: 8-10 RPM
- å¦‚æœè¶…é rate limitï¼Œæœƒè§¸ç™¼ KeyHealthTracker çš„ throttle

**OpenAI**:
- ä»˜è²»æœå‹™ï¼Œéœ€è¦ç›£æ§æˆæœ¬
- GPT-4o-mini ç›¸å°ä¾¿å®œ

---

## ğŸ” å¦‚ä½•ç¢ºèªç•¶å‰ä½¿ç”¨çš„æ¨¡å‹

### æª¢æŸ¥ Logs

```bash
# æŸ¥çœ‹ä½¿ç”¨å“ªå€‹ç³»çµ±
docker compose -f docker-compose.dev.yaml logs app | grep "Using"

# æŸ¥çœ‹ Gemini æ¨¡å‹
docker compose -f docker-compose.dev.yaml logs app | grep "Grading with Gemini"

# æŸ¥çœ‹ OpenAI æ¨¡å‹ (å¦‚æœæœ‰ fallback)
docker compose -f docker-compose.dev.yaml logs app | grep "Grading with OpenAI"
```

**é æœŸè¼¸å‡º**:
```
ğŸ¤– Using AI SDK grading system
Grading with Gemini (AI SDK) { model: 'gemini-2.5-flash' }
```

### æª¢æŸ¥è³‡æ–™åº«

```sql
-- æŸ¥çœ‹æœ€è¿‘çš„è©•åˆ†ä½¿ç”¨å“ªå€‹æ¨¡å‹
SELECT
  id,
  metadata->>'model' as model,
  metadata->>'tokens' as tokens,
  "createdAt"
FROM "GradingResult"
ORDER BY "createdAt" DESC
LIMIT 10;
```

**é æœŸçµæœ**:
- AI SDK (Gemini): `model = "gemini-2.5-flash"`
- AI SDK (OpenAI): `model = "gpt-4o-mini"`
- èˆŠç³»çµ±: `model = "gemini-2.5-flash"` (ä½† metadata æ ¼å¼å¯èƒ½ä¸åŒ)

---

## ğŸ“š ç›¸é—œæ–‡ä»¶

- **AI SDK Gemini Provider**: https://ai-sdk.dev/providers/ai-sdk-providers/google-generative-ai
- **AI SDK OpenAI Provider**: https://ai-sdk.dev/providers/ai-sdk-providers/openai
- **Gemini æ¨¡å‹æ¸…å–®**: https://ai.google.dev/gemini-api/docs/models/gemini
- **OpenAI æ¨¡å‹æ¸…å–®**: https://platform.openai.com/docs/models

---

## ç¸½çµ

**æ–°ç³»çµ±ä½¿ç”¨çš„æ¨¡å‹**:
1. **ä¸»è¦æ¨¡å‹**: Gemini 2.5 Flash (`gemini-2.5-flash`)
   - ä½ç½®: `app/services/ai-sdk-provider.server.ts:167`
   - Temperature: 0.3
   - Max Retries: 2

2. **Fallback æ¨¡å‹**: OpenAI GPT-4o-mini (`gpt-4o-mini`)
   - ä½ç½®: `app/services/ai-sdk-provider.server.ts:271`
   - Temperature: 0.1
   - Max Retries: 2

**èˆ‡èˆŠç³»çµ±ç›¸æ¯”**:
- âœ… æ¨¡å‹ç›¸åŒ (gemini-2.5-flash / gpt-4o-mini)
- âœ… Temperature ç›¸åŒ
- âš ï¸ ç§»é™¤äº† maxOutputTokens å’Œ thinkingConfig
- âœ… å¢åŠ äº† Zod schema è‡ªå‹•é©—è­‰
- âœ… ç°¡åŒ–äº† error handling
